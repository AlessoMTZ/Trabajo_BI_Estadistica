{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\AppData\\Local\\Temp\\ipykernel_5052\\153611630.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "c:\\Users\\carlo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\carlo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package cess_esp to\n",
      "[nltk_data]     C:\\Users\\carlo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cess_esp is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\carlo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\carlo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 52.5MB/s]                    \n",
      "2024-04-06 18:46:48 INFO: Downloaded file to C:\\Users\\carlo\\stanza_resources\\resources.json\n",
      "2024-04-06 18:46:48 INFO: Downloading default packages for language: es (Spanish) ...\n",
      "2024-04-06 18:46:51 INFO: File exists: C:\\Users\\carlo\\stanza_resources\\es\\default.zip\n",
      "2024-04-06 18:47:04 INFO: Finished downloading models and saved to C:\\Users\\carlo\\stanza_resources\n"
     ]
    }
   ],
   "source": [
    "## Importar las librerias\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from statistics import mode\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from langdetect import detect, LangDetectException\n",
    "from googletrans import Translator, LANGUAGES\n",
    "import string\n",
    "from num2words import num2words\n",
    "import re\n",
    "from nltk.corpus import cess_esp\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import stanza \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "\n",
    "## Descarga la información relevante de la libreria nltk\n",
    "nltk.download('punkt') # Tokenizador de palabras\n",
    "nltk.download('cess_esp') # Corpus en español\n",
    "nltk.download('stopwords') # Palabras vacias\n",
    "nltk.download('wordnet') # Sinonimos\n",
    "stanza.download('es')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importar el dataset\n",
    "filepath = 'tipo1_entrenamiento_estudiantes.csv'\n",
    "dataset = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define las contracciones del español\n",
    "contracciones = {\n",
    "    \"q\": \"que\",\n",
    "    \"d\": \"de\",\n",
    "    \"t\": \"te\",\n",
    "    \"m\": \"me\",\n",
    "    \"na\": \"nada\",\n",
    "    \"toy\": \"estoy\",\n",
    "    \"toy\": \"estoy\",\n",
    "    \"sta\": \"esta\",\n",
    "    \"tamos\": \"estamos\",\n",
    "    'verm': 'ver',\n",
    "    \"al\": \"a el\",\n",
    "    \"del\": \"de el\",\n",
    "    \"bn\": \"bien\",}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Da un listado de las palabras que no tienen mucha utilidad en español\n",
    "spanish_stopwords = set(stopwords.words('spanish'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entendimiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciaremos por entender los datos que compondrán nuestro dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nos alojamos en una casa alquilada en la ciuda...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La comida está bien, pero nada especial. Yo te...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En mi opinión, no es una como muchos usuarios ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>esta curiosa forma que asemeja una silla de mo...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lo mejor era la limonada. Me gusto la comida d...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Class\n",
       "0  Nos alojamos en una casa alquilada en la ciuda...      4\n",
       "1  La comida está bien, pero nada especial. Yo te...      3\n",
       "2  En mi opinión, no es una como muchos usuarios ...      3\n",
       "3  esta curiosa forma que asemeja una silla de mo...      4\n",
       "4  Lo mejor era la limonada. Me gusto la comida d...      2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Muestra las primeras filas del dataset\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lenguaje\n",
       "es    7868\n",
       "en       6\n",
       "pt       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisa el idioma del dataset\n",
    "analisis= dataset.copy()\n",
    "\n",
    "# #Se define una función que detecta el idioma de un texto\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except LangDetectException:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# Apply the language detection function to the first few rows as a test\n",
    "analisis['lenguaje']=dataset['Review'].apply(detect_language)\n",
    "language_counts = analisis['lenguaje'].value_counts()\n",
    "language_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>lenguaje</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>Es tremendo, estuve en este lugar y la comida ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>A must when you're in Bogota and it's just in ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>First time in Colombia and the Hotel and servi...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3368</th>\n",
       "      <td>My expectations about this hotel were high due...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4835</th>\n",
       "      <td>This mercado is just like every mercado that I...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6563</th>\n",
       "      <td>The other night LDV , Nuevo, service slow , fo...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review lenguaje\n",
       "552   Es tremendo, estuve en este lugar y la comida ...       en\n",
       "743   A must when you're in Bogota and it's just in ...       en\n",
       "1497  First time in Colombia and the Hotel and servi...       en\n",
       "3368  My expectations about this hotel were high due...       en\n",
       "4835  This mercado is just like every mercado that I...       en\n",
       "6563  The other night LDV , Nuevo, service slow , fo...       en"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Muestra las filas en inglés\n",
    "\n",
    "# Filter the dataset for reviews estimated to be in English\n",
    "english_reviews = analisis[analisis['lenguaje'] == 'en']\n",
    "\n",
    "# Show the filtered rows\n",
    "english_reviews[['Review', 'lenguaje']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>lenguaje</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>Parada obrigatório em Havana para tomar o icôn...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review lenguaje\n",
       "1932  Parada obrigatório em Havana para tomar o icôn...       pt"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Muestra las filas en portugués\n",
    "\n",
    "# Filter the dataset for reviews estimated to be in English\n",
    "portuguese_reviews = analisis[analisis['lenguaje'] == 'pt']\n",
    "\n",
    "# Show the filtered rows\n",
    "portuguese_reviews[['Review', 'lenguaje']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7875 entries, 0 to 7874\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Review  7875 non-null   object\n",
      " 1   Class   7875 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 123.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Revisa la información del dataset\n",
    "dataset.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nótese que no existe ningún dato faltante, también que todos los elementos de la clase son del tipo entero, por lo que no hay errores en la variable numérica. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "5    2350\n",
       "4    1971\n",
       "3    1568\n",
       "2    1173\n",
       "1     813\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribución de la columna Class\n",
    "dataset['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nótese que la distribución de la información respecto a la columna clase está desbalanceada, entonces hay más datos clasificados en las clases más altas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Class</th>\n",
       "      <th>lenguaje</th>\n",
       "      <th>NumPalabras</th>\n",
       "      <th>Moda</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nos alojamos en una casa alquilada en la ciuda...</td>\n",
       "      <td>4</td>\n",
       "      <td>es</td>\n",
       "      <td>416</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La comida está bien, pero nada especial. Yo te...</td>\n",
       "      <td>3</td>\n",
       "      <td>es</td>\n",
       "      <td>263</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En mi opinión, no es una como muchos usuarios ...</td>\n",
       "      <td>3</td>\n",
       "      <td>es</td>\n",
       "      <td>612</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>esta curiosa forma que asemeja una silla de mo...</td>\n",
       "      <td>4</td>\n",
       "      <td>es</td>\n",
       "      <td>180</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lo mejor era la limonada. Me gusto la comida d...</td>\n",
       "      <td>2</td>\n",
       "      <td>es</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7870</th>\n",
       "      <td>El motivo de mi estancia fue porque vine a un ...</td>\n",
       "      <td>3</td>\n",
       "      <td>es</td>\n",
       "      <td>624</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7871</th>\n",
       "      <td>Es difícil revisar el castillo porque apenas p...</td>\n",
       "      <td>3</td>\n",
       "      <td>es</td>\n",
       "      <td>609</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7872</th>\n",
       "      <td>Si vas a Mérida no puedes perderte de este lug...</td>\n",
       "      <td>5</td>\n",
       "      <td>es</td>\n",
       "      <td>168</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7873</th>\n",
       "      <td>Este imperdible sitio, que lleva el nombre del...</td>\n",
       "      <td>5</td>\n",
       "      <td>es</td>\n",
       "      <td>424</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7874</th>\n",
       "      <td>Festejando Dia del Amor y Amistad\\r\\n\\r\\nTe re...</td>\n",
       "      <td>3</td>\n",
       "      <td>es</td>\n",
       "      <td>265</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7875 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review  Class lenguaje  \\\n",
       "0     Nos alojamos en una casa alquilada en la ciuda...      4       es   \n",
       "1     La comida está bien, pero nada especial. Yo te...      3       es   \n",
       "2     En mi opinión, no es una como muchos usuarios ...      3       es   \n",
       "3     esta curiosa forma que asemeja una silla de mo...      4       es   \n",
       "4     Lo mejor era la limonada. Me gusto la comida d...      2       es   \n",
       "...                                                 ...    ...      ...   \n",
       "7870  El motivo de mi estancia fue porque vine a un ...      3       es   \n",
       "7871  Es difícil revisar el castillo porque apenas p...      3       es   \n",
       "7872  Si vas a Mérida no puedes perderte de este lug...      5       es   \n",
       "7873  Este imperdible sitio, que lleva el nombre del...      5       es   \n",
       "7874  Festejando Dia del Amor y Amistad\\r\\n\\r\\nTe re...      3       es   \n",
       "\n",
       "      NumPalabras  Moda  Max  Min  \n",
       "0             416     2   13    1  \n",
       "1             263     2   14    1  \n",
       "2             612     3   16    1  \n",
       "3             180     2    9    2  \n",
       "4              88     2    9    1  \n",
       "...           ...   ...  ...  ...  \n",
       "7870          624     2   13    0  \n",
       "7871          609     2   15    1  \n",
       "7872          168     3    9    1  \n",
       "7873          424     2   18    0  \n",
       "7874          265     2   13    0  \n",
       "\n",
       "[7875 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisa la información de las palabras en lo que respecta a la variable categórica.\n",
    "\n",
    "\n",
    "analisis['NumPalabras']= [len(word) for word in dataset['Review']]\n",
    "analisis['Moda'] = analisis['Review'].apply(lambda review: mode([len(word) for word in review.split()]) if review else None)\n",
    "analisis['Max'] = [max([len(word) for word in review.split(' ')]) for review in analisis['Review']]\n",
    "analisis['Min'] = [min([len(word) for word in review.split(' ')]) for review in analisis['Review']]\n",
    "\n",
    "analisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la preparación de los datos se van a realizar los siguientes pasos:\n",
    "* Traducción de datos \n",
    "* Limpieza de datos\n",
    "* Tokenización\n",
    "* Normalización\n",
    "* Lematización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un dataset diferente para hacer la preparación de los datos\n",
    "prepData= analisis.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traducción de los datos ajenos al idioma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Review lenguaje\n",
      "1932  Parada obligatoria en La Habana para tomar la ...       pt\n",
      "                                                 Review lenguaje\n",
      "552   Es tremendo, estuve en este lugar y la comida ...       en\n",
      "743   Una visita obligada cuando estás en Bogotá y e...       en\n",
      "1497  La primera vez en Colombia y el hotel y el ser...       en\n",
      "3368  Mis expectativas sobre este hotel fueron altas...       en\n",
      "4835  Este mercado es como todos los mercados que he...       en\n",
      "6563  La otra noche LDV, Nuevo, servicio lento, comi...       en\n"
     ]
    }
   ],
   "source": [
    "#Se traducen los idiomas ajenos al lenguaje español\n",
    "translator = Translator()\n",
    "def translate_to_spanish(text):\n",
    "    # Detecta el idioma del texto\n",
    "    detected = translator.detect(text)\n",
    "    \n",
    "    # Verifica si el texto ya está en español\n",
    "    if detected.lang == 'es':\n",
    "        return text\n",
    "    \n",
    "    # Si el texto no está en español, lo traduce al español\n",
    "    translated = translator.translate(text, src=detected.lang, dest='es')\n",
    "    return translated.text\n",
    "if 'lenguaje' in prepData.columns:\n",
    "    prepData.loc[prepData['lenguaje'] == 'pt', 'Review'] = prepData.loc[prepData['lenguaje'] == 'pt', 'Review'].apply(lambda x: translate_to_spanish(x))\n",
    "    prepData.loc[prepData['lenguaje'] == 'en', 'Review'] = prepData.loc[prepData['lenguaje'] == 'en', 'Review'].apply(lambda x: translate_to_spanish(x))\n",
    "    portuguese_reviews = prepData[prepData['lenguaje'] == 'pt']\n",
    "    portuguese_reviews[['Review', 'lenguaje']]\n",
    "    #Verifica que se haya traducido el portugués\n",
    "    print(portuguese_reviews[['Review', 'lenguaje']])\n",
    "    english_reviews = prepData[prepData['lenguaje'] == 'en']\n",
    "    #Verifica que se haya traducido el inglés\n",
    "    print(english_reviews[['Review', 'lenguaje']])\n",
    "    prepData.drop('lenguaje', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la limpieza de datos se va a garantizar que :\n",
    "* Se deja todo en minuscula\n",
    "* Remover carácteres no deseados\n",
    "* Remover puntuación\n",
    "* Manejar valores numéricos\n",
    "* Remover palabras que no tienen un gran sentimiento (StopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se deja todo en minuscula\n",
    "def lower_case_words(tokenized_words):\n",
    "    \"\"\"Convert all words in a list to lowercase.\"\"\"\n",
    "    # Use a list comprehension to convert each word in the list to lowercase\n",
    "    lowercased_words = [word.lower() for word in tokenized_words]\n",
    "    \n",
    "    return lowercased_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimina todos los elementos que no son necesarios y no se buscan utilizar\n",
    "\n",
    "def remove_unwanted_characters_from_tokens(tokenized_words):\n",
    "    \"\"\"Remove unwanted non-ASCII characters from a list of tokenized words, retaining Spanish characters.\"\"\"\n",
    "    # Include the Spanish alphabet, both lowercase and uppercase, digits, and common punctuation\n",
    "    allowed_characters = set(\"abcdefghijklmnopqrstuvwxyzáéíóúüñABCDEFGHIJKLMNOPQRSTUVWXYZÁÉÍÓÚÜÑ \" + string.digits + string.punctuation)\n",
    "    \n",
    "    # Initialize an empty list to hold the cleaned words\n",
    "    new_words = []\n",
    "    \n",
    "    # Iterate over each word in the list of tokenized words\n",
    "    for word in tokenized_words:\n",
    "        # Filter each word to include only allowed characters\n",
    "        cleaned_word = ''.join(char for char in word if char in allowed_characters)\n",
    "        # Append the cleaned word to the new list\n",
    "        if cleaned_word == word:\n",
    "            # If they are the same, it means the word contains only allowed characters, so append it to the list\n",
    "            new_words.append(cleaned_word)\n",
    "    \n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remueve la punctuación dentro de cada palabra\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words, with explicit support for Unicode characters.\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word is not None:\n",
    "            # Use \\w for word characters, \\s for whitespace, and ensure Unicode support\n",
    "            new_word = re.sub(r'[^\\w\\s]', '', word, flags=re.UNICODE)\n",
    "            if new_word != '':\n",
    "                new_words.append(new_word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierte los números a palabras\n",
    "def convert_numbers_to_words(words):\n",
    "    \"\"\"Convert all numbers in a text to their word representation in the specified language.\"\"\"\n",
    "    \n",
    "    # Convert each word\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            word= float(word)\n",
    "            # Convert the numerical word to its word representation\n",
    "            word_in_text = num2words(word, lang='es')\n",
    "            new_words.append(word_in_text)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remueve las stopwords o palabras sin mucha prioridad en el analisis\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    # Filter out any words that are in the list of stop words\n",
    "    filtered_words = [word for word in words if word not in spanish_stopwords]\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(words):\n",
    "    \"\"\"Preprocess a list of tokenized words\"\"\"\n",
    "    # Remove unwanted characters\n",
    "    words = remove_unwanted_characters_from_tokens(words)\n",
    "    # Convert to lowercase\n",
    "    words = lower_case_words(words)\n",
    "    # Convert numbers to words\n",
    "    words = convert_numbers_to_words(words)\n",
    "    # Remove punctuation\n",
    "    words = remove_punctuation(words)\n",
    "    # Remove stop words\n",
    "    words = remove_stopwords(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La tokenización divide el texto en unidades más pequeñas, como palabras o símbolos, para análisis. La usaremos para descomponer el texto en tokens individuales, facilitando análisis posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Class</th>\n",
       "      <th>NumPalabras</th>\n",
       "      <th>Moda</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nos alojamos en una casa alquilada en la ciuda...</td>\n",
       "      <td>4</td>\n",
       "      <td>416</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La comida está bien, pero nada especial. Yo te...</td>\n",
       "      <td>3</td>\n",
       "      <td>263</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En mi opinión, no es una como muchos usuarios ...</td>\n",
       "      <td>3</td>\n",
       "      <td>612</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>esta curiosa forma que asemeja una silla de mo...</td>\n",
       "      <td>4</td>\n",
       "      <td>180</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lo mejor era la limonada. Me gusto la comida d...</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7870</th>\n",
       "      <td>El motivo de mi estancia fue porque vine a un ...</td>\n",
       "      <td>3</td>\n",
       "      <td>624</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7871</th>\n",
       "      <td>Es difícil revisar el castillo porque apenas p...</td>\n",
       "      <td>3</td>\n",
       "      <td>609</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7872</th>\n",
       "      <td>Si vas a Mérida no puedes perderte de este lug...</td>\n",
       "      <td>5</td>\n",
       "      <td>168</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7873</th>\n",
       "      <td>Este imperdible sitio, que lleva el nombre de ...</td>\n",
       "      <td>5</td>\n",
       "      <td>424</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7874</th>\n",
       "      <td>Festejando Dia de el Amor y Amistad\\r\\n\\r\\nTe ...</td>\n",
       "      <td>3</td>\n",
       "      <td>265</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7875 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review  Class  NumPalabras  \\\n",
       "0     Nos alojamos en una casa alquilada en la ciuda...      4          416   \n",
       "1     La comida está bien, pero nada especial. Yo te...      3          263   \n",
       "2     En mi opinión, no es una como muchos usuarios ...      3          612   \n",
       "3     esta curiosa forma que asemeja una silla de mo...      4          180   \n",
       "4     Lo mejor era la limonada. Me gusto la comida d...      2           88   \n",
       "...                                                 ...    ...          ...   \n",
       "7870  El motivo de mi estancia fue porque vine a un ...      3          624   \n",
       "7871  Es difícil revisar el castillo porque apenas p...      3          609   \n",
       "7872  Si vas a Mérida no puedes perderte de este lug...      5          168   \n",
       "7873  Este imperdible sitio, que lleva el nombre de ...      5          424   \n",
       "7874  Festejando Dia de el Amor y Amistad\\r\\n\\r\\nTe ...      3          265   \n",
       "\n",
       "      Moda  Max  Min  \n",
       "0        2   13    1  \n",
       "1        2   14    1  \n",
       "2        3   16    1  \n",
       "3        2    9    2  \n",
       "4        2    9    1  \n",
       "...    ...  ...  ...  \n",
       "7870     2   13    0  \n",
       "7871     2   15    1  \n",
       "7872     3    9    1  \n",
       "7873     2   18    0  \n",
       "7874     2   13    0  \n",
       "\n",
       "[7875 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Expandir las contracciones y reemplazarlas\n",
    "def expandir_contracciones(texto, contracciones_dict):\n",
    "    \"\"\"\n",
    "    Expande las contracciones encontradas en el texto basándose en un diccionario de contracciones.\n",
    "    \"\"\"\n",
    "    # Asegurarse de que la expresión regular coincide solo con palabras completas. \n",
    "    # \\b es un límite de palabra, lo que ayuda a coincidir solo palabras completas.\n",
    "    contracciones_re = re.compile(r'\\b(%s)\\b' % '|'.join(map(re.escape, contracciones_dict.keys())))\n",
    "\n",
    "    def reemplazo(match):\n",
    "        return contracciones_dict[match.group(0)]\n",
    "\n",
    "    texto_expandido = contracciones_re.sub(reemplazo, texto)\n",
    "    \n",
    "    return texto_expandido\n",
    "\n",
    "prepData['Review'] = prepData['Review'].apply(expandir_contracciones, contracciones_dict=contracciones)\n",
    "prepData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Class</th>\n",
       "      <th>NumPalabras</th>\n",
       "      <th>Moda</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nos alojamos en una casa alquilada en la ciuda...</td>\n",
       "      <td>4</td>\n",
       "      <td>416</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>[Nos, alojamos, en, una, casa, alquilada, en, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La comida está bien, pero nada especial. Yo te...</td>\n",
       "      <td>3</td>\n",
       "      <td>263</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>[La, comida, está, bien, ,, pero, nada, especi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En mi opinión, no es una como muchos usuarios ...</td>\n",
       "      <td>3</td>\n",
       "      <td>612</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>[En, mi, opinión, ,, no, es, una, como, muchos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>esta curiosa forma que asemeja una silla de mo...</td>\n",
       "      <td>4</td>\n",
       "      <td>180</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>[esta, curiosa, forma, que, asemeja, una, sill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lo mejor era la limonada. Me gusto la comida d...</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[Lo, mejor, era, la, limonada, ., Me, gusto, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Class  NumPalabras  \\\n",
       "0  Nos alojamos en una casa alquilada en la ciuda...      4          416   \n",
       "1  La comida está bien, pero nada especial. Yo te...      3          263   \n",
       "2  En mi opinión, no es una como muchos usuarios ...      3          612   \n",
       "3  esta curiosa forma que asemeja una silla de mo...      4          180   \n",
       "4  Lo mejor era la limonada. Me gusto la comida d...      2           88   \n",
       "\n",
       "   Moda  Max  Min                                              words  \n",
       "0     2   13    1  [Nos, alojamos, en, una, casa, alquilada, en, ...  \n",
       "1     2   14    1  [La, comida, está, bien, ,, pero, nada, especi...  \n",
       "2     3   16    1  [En, mi, opinión, ,, no, es, una, como, muchos...  \n",
       "3     2    9    2  [esta, curiosa, forma, que, asemeja, una, sill...  \n",
       "4     2    9    1  [Lo, mejor, era, la, limonada, ., Me, gusto, l...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenizar\n",
    "def nltk_spanish_tokenizer(text):\n",
    "    return word_tokenize(text, language='spanish')\n",
    "prepData['words'] = prepData['Review'].apply(lambda x: word_tokenize(x, language='spanish'))\n",
    "prepData.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Nos, alojamos, en, una, casa, alquilada, en, ...\n",
       "1       [La, comida, está, bien, ,, pero, nada, especi...\n",
       "2       [En, mi, opinión, ,, no, es, una, como, muchos...\n",
       "3       [esta, curiosa, forma, que, asemeja, una, sill...\n",
       "4       [Lo, mejor, era, la, limonada, ., Me, gusto, l...\n",
       "                              ...                        \n",
       "7870    [El, motivo, de, mi, estancia, fue, porque, vi...\n",
       "7871    [Es, difícil, revisar, el, castillo, porque, a...\n",
       "7872    [Si, vas, a, Mérida, no, puedes, perderte, de,...\n",
       "7873    [Este, imperdible, sitio, ,, que, lleva, el, n...\n",
       "7874    [Festejando, Dia, de, el, Amor, y, Amistad, Te...\n",
       "Name: words, Length: 7875, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Elimina los valores nulos del conjunto de palabras\n",
    "prepData['words'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7875 entries, 0 to 7874\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Review       7875 non-null   object\n",
      " 1   Class        7875 non-null   int64 \n",
      " 2   NumPalabras  7875 non-null   int64 \n",
      " 3   Moda         7875 non-null   int64 \n",
      " 4   Max          7875 non-null   int64 \n",
      " 5   Min          7875 non-null   int64 \n",
      " 6   words        7875 non-null   object\n",
      "dtypes: int64(5), object(2)\n",
      "memory usage: 430.8+ KB\n"
     ]
    }
   ],
   "source": [
    "prepData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Class</th>\n",
       "      <th>NumPalabras</th>\n",
       "      <th>Moda</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>words</th>\n",
       "      <th>words1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nos alojamos en una casa alquilada en la ciuda...</td>\n",
       "      <td>4</td>\n",
       "      <td>416</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>[Nos, alojamos, en, una, casa, alquilada, en, ...</td>\n",
       "      <td>[alojamos, casa, alquilada, ciudad, amurallada...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La comida está bien, pero nada especial. Yo te...</td>\n",
       "      <td>3</td>\n",
       "      <td>263</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>[La, comida, está, bien, ,, pero, nada, especi...</td>\n",
       "      <td>[comida, bien, especial, mejor, comida, mexcan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En mi opinión, no es una como muchos usuarios ...</td>\n",
       "      <td>3</td>\n",
       "      <td>612</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>[En, mi, opinión, ,, no, es, una, como, muchos...</td>\n",
       "      <td>[opinión, usuarios, reclaman, gran, paladar, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>esta curiosa forma que asemeja una silla de mo...</td>\n",
       "      <td>4</td>\n",
       "      <td>180</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>[esta, curiosa, forma, que, asemeja, una, sill...</td>\n",
       "      <td>[curiosa, forma, asemeja, silla, montar, ahi, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lo mejor era la limonada. Me gusto la comida d...</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[Lo, mejor, era, la, limonada, ., Me, gusto, l...</td>\n",
       "      <td>[mejor, limonada, gusto, comida, mundo, sosa, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Class  NumPalabras  \\\n",
       "0  Nos alojamos en una casa alquilada en la ciuda...      4          416   \n",
       "1  La comida está bien, pero nada especial. Yo te...      3          263   \n",
       "2  En mi opinión, no es una como muchos usuarios ...      3          612   \n",
       "3  esta curiosa forma que asemeja una silla de mo...      4          180   \n",
       "4  Lo mejor era la limonada. Me gusto la comida d...      2           88   \n",
       "\n",
       "   Moda  Max  Min                                              words  \\\n",
       "0     2   13    1  [Nos, alojamos, en, una, casa, alquilada, en, ...   \n",
       "1     2   14    1  [La, comida, está, bien, ,, pero, nada, especi...   \n",
       "2     3   16    1  [En, mi, opinión, ,, no, es, una, como, muchos...   \n",
       "3     2    9    2  [esta, curiosa, forma, que, asemeja, una, sill...   \n",
       "4     2    9    1  [Lo, mejor, era, la, limonada, ., Me, gusto, l...   \n",
       "\n",
       "                                              words1  \n",
       "0  [alojamos, casa, alquilada, ciudad, amurallada...  \n",
       "1  [comida, bien, especial, mejor, comida, mexcan...  \n",
       "2  [opinión, usuarios, reclaman, gran, paladar, p...  \n",
       "3  [curiosa, forma, asemeja, silla, montar, ahi, ...  \n",
       "4  [mejor, limonada, gusto, comida, mundo, sosa, ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aplica el procesamiento básico\n",
    "prepData['words1']=prepData['words'].apply(preprocessing)\n",
    "prepData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proceso de transformar el texto a una forma estándar para facilitar su análisis. La utilizaremos para estandarizar el texto, lo que simplificará el procesamiento posterior del texto en los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemmer\n",
    "\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    # Stem each word in the list of words\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return stemmed_words\n",
    "\n",
    "#This is just for trying the stemmer\n",
    "def stemExample(text):\n",
    "   return [stemmer.stem(word) for word in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Class</th>\n",
       "      <th>NumPalabras</th>\n",
       "      <th>Moda</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>words</th>\n",
       "      <th>words1</th>\n",
       "      <th>words2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nos alojamos en una casa alquilada en la ciuda...</td>\n",
       "      <td>4</td>\n",
       "      <td>416</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>[Nos, alojamos, en, una, casa, alquilada, en, ...</td>\n",
       "      <td>[alojamos, casa, alquilada, ciudad, amurallada...</td>\n",
       "      <td>[aloj, cas, alquil, ciud, amurall, parec, tan,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La comida está bien, pero nada especial. Yo te...</td>\n",
       "      <td>3</td>\n",
       "      <td>263</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>[La, comida, está, bien, ,, pero, nada, especi...</td>\n",
       "      <td>[comida, bien, especial, mejor, comida, mexcan...</td>\n",
       "      <td>[com, bien, especial, mejor, com, mexc, unid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En mi opinión, no es una como muchos usuarios ...</td>\n",
       "      <td>3</td>\n",
       "      <td>612</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>[En, mi, opinión, ,, no, es, una, como, muchos...</td>\n",
       "      <td>[opinión, usuarios, reclaman, gran, paladar, p...</td>\n",
       "      <td>[opinion, usuari, reclam, gran, palad, parec, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>esta curiosa forma que asemeja una silla de mo...</td>\n",
       "      <td>4</td>\n",
       "      <td>180</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>[esta, curiosa, forma, que, asemeja, una, sill...</td>\n",
       "      <td>[curiosa, forma, asemeja, silla, montar, ahi, ...</td>\n",
       "      <td>[curios, form, asemej, sill, mont, ahi, nombr,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lo mejor era la limonada. Me gusto la comida d...</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[Lo, mejor, era, la, limonada, ., Me, gusto, l...</td>\n",
       "      <td>[mejor, limonada, gusto, comida, mundo, sosa, ...</td>\n",
       "      <td>[mejor, limon, gust, com, mund, sos, fri]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Class  NumPalabras  \\\n",
       "0  Nos alojamos en una casa alquilada en la ciuda...      4          416   \n",
       "1  La comida está bien, pero nada especial. Yo te...      3          263   \n",
       "2  En mi opinión, no es una como muchos usuarios ...      3          612   \n",
       "3  esta curiosa forma que asemeja una silla de mo...      4          180   \n",
       "4  Lo mejor era la limonada. Me gusto la comida d...      2           88   \n",
       "\n",
       "   Moda  Max  Min                                              words  \\\n",
       "0     2   13    1  [Nos, alojamos, en, una, casa, alquilada, en, ...   \n",
       "1     2   14    1  [La, comida, está, bien, ,, pero, nada, especi...   \n",
       "2     3   16    1  [En, mi, opinión, ,, no, es, una, como, muchos...   \n",
       "3     2    9    2  [esta, curiosa, forma, que, asemeja, una, sill...   \n",
       "4     2    9    1  [Lo, mejor, era, la, limonada, ., Me, gusto, l...   \n",
       "\n",
       "                                              words1  \\\n",
       "0  [alojamos, casa, alquilada, ciudad, amurallada...   \n",
       "1  [comida, bien, especial, mejor, comida, mexcan...   \n",
       "2  [opinión, usuarios, reclaman, gran, paladar, p...   \n",
       "3  [curiosa, forma, asemeja, silla, montar, ahi, ...   \n",
       "4  [mejor, limonada, gusto, comida, mundo, sosa, ...   \n",
       "\n",
       "                                              words2  \n",
       "0  [aloj, cas, alquil, ciud, amurall, parec, tan,...  \n",
       "1  [com, bien, especial, mejor, com, mexc, unid, ...  \n",
       "2  [opinion, usuari, reclam, gran, palad, parec, ...  \n",
       "3  [curios, form, asemej, sill, mont, ahi, nombr,...  \n",
       "4          [mejor, limon, gust, com, mund, sos, fri]  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Apply Stemmer to the words\n",
    "prepData['words2'] = prepData['words1'].apply(stem_words)\n",
    "prepData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lematizacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es un proceso lingüístico que reduce las palabras a su forma base o raíz, conocida como lema. Se utiliza para normalizar palabras y reducir la variabilidad léxica, lo que facilita el análisis de texto al agrupar palabras similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "nlp = spacy.load('es_core_news_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.es.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_and_remove_stopwords(texto):\n",
    "    doc = nlp(texto)\n",
    "    lemmatized_tokens = [token.lemma_ for token in doc if not token.is_stop]  # Remover stopwords\n",
    "    lemmatized_text = ' '.join(lemmatized_tokens)\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Class</th>\n",
       "      <th>NumPalabras</th>\n",
       "      <th>Moda</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>words</th>\n",
       "      <th>words1</th>\n",
       "      <th>words2</th>\n",
       "      <th>lemmatized_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nos alojamos en una casa alquilada en la ciuda...</td>\n",
       "      <td>4</td>\n",
       "      <td>416</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>[Nos, alojamos, en, una, casa, alquilada, en, ...</td>\n",
       "      <td>[alojamos, casa, alquilada, ciudad, amurallada...</td>\n",
       "      <td>[aloj, cas, alquil, ciud, amurall, parec, tan,...</td>\n",
       "      <td>alogir casa alquilado ciudad amurallado . pare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La comida está bien, pero nada especial. Yo te...</td>\n",
       "      <td>3</td>\n",
       "      <td>263</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>[La, comida, está, bien, ,, pero, nada, especi...</td>\n",
       "      <td>[comida, bien, especial, mejor, comida, mexcan...</td>\n",
       "      <td>[com, bien, especial, mejor, com, mexc, unid, ...</td>\n",
       "      <td>comida , especial . comida Mexcan Unidos . mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En mi opinión, no es una como muchos usuarios ...</td>\n",
       "      <td>3</td>\n",
       "      <td>612</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>[En, mi, opinión, ,, no, es, una, como, muchos...</td>\n",
       "      <td>[opinión, usuarios, reclaman, gran, paladar, p...</td>\n",
       "      <td>[opinion, usuari, reclam, gran, palad, parec, ...</td>\n",
       "      <td>opinión , usuario reclamar . paladar parada gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>esta curiosa forma que asemeja una silla de mo...</td>\n",
       "      <td>4</td>\n",
       "      <td>180</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>[esta, curiosa, forma, que, asemeja, una, sill...</td>\n",
       "      <td>[curiosa, forma, asemeja, silla, montar, ahi, ...</td>\n",
       "      <td>[curios, form, asemej, sill, mont, ahi, nombr,...</td>\n",
       "      <td>curioso forma asemejar silla montar nombre ico...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lo mejor era la limonada. Me gusto la comida d...</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[Lo, mejor, era, la, limonada, ., Me, gusto, l...</td>\n",
       "      <td>[mejor, limonada, gusto, comida, mundo, sosa, ...</td>\n",
       "      <td>[mejor, limon, gust, com, mund, sos, fri]</td>\n",
       "      <td>limonado . gustar comida mundo sós frío .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Class  NumPalabras  \\\n",
       "0  Nos alojamos en una casa alquilada en la ciuda...      4          416   \n",
       "1  La comida está bien, pero nada especial. Yo te...      3          263   \n",
       "2  En mi opinión, no es una como muchos usuarios ...      3          612   \n",
       "3  esta curiosa forma que asemeja una silla de mo...      4          180   \n",
       "4  Lo mejor era la limonada. Me gusto la comida d...      2           88   \n",
       "\n",
       "   Moda  Max  Min                                              words  \\\n",
       "0     2   13    1  [Nos, alojamos, en, una, casa, alquilada, en, ...   \n",
       "1     2   14    1  [La, comida, está, bien, ,, pero, nada, especi...   \n",
       "2     3   16    1  [En, mi, opinión, ,, no, es, una, como, muchos...   \n",
       "3     2    9    2  [esta, curiosa, forma, que, asemeja, una, sill...   \n",
       "4     2    9    1  [Lo, mejor, era, la, limonada, ., Me, gusto, l...   \n",
       "\n",
       "                                              words1  \\\n",
       "0  [alojamos, casa, alquilada, ciudad, amurallada...   \n",
       "1  [comida, bien, especial, mejor, comida, mexcan...   \n",
       "2  [opinión, usuarios, reclaman, gran, paladar, p...   \n",
       "3  [curiosa, forma, asemeja, silla, montar, ahi, ...   \n",
       "4  [mejor, limonada, gusto, comida, mundo, sosa, ...   \n",
       "\n",
       "                                              words2  \\\n",
       "0  [aloj, cas, alquil, ciud, amurall, parec, tan,...   \n",
       "1  [com, bien, especial, mejor, com, mexc, unid, ...   \n",
       "2  [opinion, usuari, reclam, gran, palad, parec, ...   \n",
       "3  [curios, form, asemej, sill, mont, ahi, nombr,...   \n",
       "4          [mejor, limon, gust, com, mund, sos, fri]   \n",
       "\n",
       "                                   lemmatized_review  \n",
       "0  alogir casa alquilado ciudad amurallado . pare...  \n",
       "1  comida , especial . comida Mexcan Unidos . mar...  \n",
       "2  opinión , usuario reclamar . paladar parada gr...  \n",
       "3  curioso forma asemejar silla montar nombre ico...  \n",
       "4          limonado . gustar comida mundo sós frío .  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepData['lemmatized_review'] = prepData['Review'].apply(lemmatize_and_remove_stopwords)\n",
    "prepData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación e implementación de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que tenemos nuestros datos procesados, procederemos a aplicar diferentes modelos sobre nuestro dataframe procesado. La regresión logística, el bosque aleatorio y la red neuronal son los modelos que elegimos implementar. La regresión logística es adecuada para problemas de clasificación binaria y multinomial, como este. El bosque aleatorio es robusto, maneja bien características irrelevantes y no linealidades. Las redes neuronales, con su capacidad para aprender representaciones complejas, son útiles para capturar relaciones no lineales en los datos. Procedemos a calcular la precisión (accuracy) para cada alternativa para concluir cuál soluciona mejor el problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Class</th>\n",
       "      <th>NumPalabras</th>\n",
       "      <th>Moda</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>words</th>\n",
       "      <th>words1</th>\n",
       "      <th>words2</th>\n",
       "      <th>lemmatized_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nos alojamos en una casa alquilada en la ciuda...</td>\n",
       "      <td>4</td>\n",
       "      <td>416</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>aloj cas alquil ciud amurall parec tan segur c...</td>\n",
       "      <td>[alojamos, casa, alquilada, ciudad, amurallada...</td>\n",
       "      <td>[aloj, cas, alquil, ciud, amurall, parec, tan,...</td>\n",
       "      <td>yo alogir en uno casa alquilado en el ciudad a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La comida está bien, pero nada especial. Yo te...</td>\n",
       "      <td>3</td>\n",
       "      <td>263</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>com bien especial mejor com mexc unid margarit...</td>\n",
       "      <td>[comida, bien, especial, mejor, comida, mexcan...</td>\n",
       "      <td>[com, bien, especial, mejor, com, mexc, unid, ...</td>\n",
       "      <td>el comida estar bien , pero nada especial . yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En mi opinión, no es una como muchos usuarios ...</td>\n",
       "      <td>3</td>\n",
       "      <td>612</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>opinion usuari reclam gran palad parec ser par...</td>\n",
       "      <td>[opinión, usuarios, reclaman, gran, paladar, p...</td>\n",
       "      <td>[opinion, usuari, reclam, gran, palad, parec, ...</td>\n",
       "      <td>en mi opinión , no ser uno como mucho usuario ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>esta curiosa forma que asemeja una silla de mo...</td>\n",
       "      <td>4</td>\n",
       "      <td>180</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>curios form asemej sill mont ahi nombr icon ci...</td>\n",
       "      <td>[curiosa, forma, asemeja, silla, montar, ahi, ...</td>\n",
       "      <td>[curios, form, asemej, sill, mont, ahi, nombr,...</td>\n",
       "      <td>este curioso forma que asemejar uno silla de m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lo mejor era la limonada. Me gusto la comida d...</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>mejor limon gust com mund sos fri</td>\n",
       "      <td>[mejor, limonada, gusto, comida, mundo, sosa, ...</td>\n",
       "      <td>[mejor, limon, gust, com, mund, sos, fri]</td>\n",
       "      <td>él mejor ser el limonado . yo gustar el comida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7870</th>\n",
       "      <td>El motivo de mi estancia fue porque vine a un ...</td>\n",
       "      <td>3</td>\n",
       "      <td>624</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>motiv estanci vin congres medic hosped lug ins...</td>\n",
       "      <td>[motivo, estancia, vine, congreso, medico, hos...</td>\n",
       "      <td>[motiv, estanci, vin, congres, medic, hosped, ...</td>\n",
       "      <td>el motivo de mi estancia ser porque venir a un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7871</th>\n",
       "      <td>Es difícil revisar el castillo porque apenas p...</td>\n",
       "      <td>3</td>\n",
       "      <td>609</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>dificil revis castill apen pod camin sofoc cal...</td>\n",
       "      <td>[difícil, revisar, castillo, apenas, podíamos,...</td>\n",
       "      <td>[dificil, revis, castill, apen, pod, camin, so...</td>\n",
       "      <td>ser difícil revisar el castillo porque apenas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7872</th>\n",
       "      <td>Si vas a Mérida no puedes perderte de este lug...</td>\n",
       "      <td>5</td>\n",
       "      <td>168</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>si vas mer pued perdert lug nuev sucursal ampl...</td>\n",
       "      <td>[si, vas, mérida, puedes, perderte, lugar, nue...</td>\n",
       "      <td>[si, vas, mer, pued, perdert, lug, nuev, sucur...</td>\n",
       "      <td>si ir a Mérida no poder perderte de este lugar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7873</th>\n",
       "      <td>Este imperdible sitio, que lleva el nombre de ...</td>\n",
       "      <td>5</td>\n",
       "      <td>424</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>imperd siti llev nombr conquist joy urbanasu a...</td>\n",
       "      <td>[imperdible, sitio, lleva, nombre, conquistado...</td>\n",
       "      <td>[imperd, siti, llev, nombr, conquist, joy, urb...</td>\n",
       "      <td>este imperdible sitio , que llevar el nombre d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7874</th>\n",
       "      <td>Festejando Dia de el Amor y Amistad\\r\\n\\r\\nTe ...</td>\n",
       "      <td>3</td>\n",
       "      <td>265</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>festej dia amor amist remont restaur cafet par...</td>\n",
       "      <td>[festejando, dia, amor, amistad, remonta, rest...</td>\n",
       "      <td>[festej, dia, amor, amist, remont, restaur, ca...</td>\n",
       "      <td>Festejando Dia de el Amor y Amistad \\r\\n\\r\\n t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7875 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review  Class  NumPalabras  \\\n",
       "0     Nos alojamos en una casa alquilada en la ciuda...      4          416   \n",
       "1     La comida está bien, pero nada especial. Yo te...      3          263   \n",
       "2     En mi opinión, no es una como muchos usuarios ...      3          612   \n",
       "3     esta curiosa forma que asemeja una silla de mo...      4          180   \n",
       "4     Lo mejor era la limonada. Me gusto la comida d...      2           88   \n",
       "...                                                 ...    ...          ...   \n",
       "7870  El motivo de mi estancia fue porque vine a un ...      3          624   \n",
       "7871  Es difícil revisar el castillo porque apenas p...      3          609   \n",
       "7872  Si vas a Mérida no puedes perderte de este lug...      5          168   \n",
       "7873  Este imperdible sitio, que lleva el nombre de ...      5          424   \n",
       "7874  Festejando Dia de el Amor y Amistad\\r\\n\\r\\nTe ...      3          265   \n",
       "\n",
       "      Moda  Max  Min                                              words  \\\n",
       "0        2   13    1  aloj cas alquil ciud amurall parec tan segur c...   \n",
       "1        2   14    1  com bien especial mejor com mexc unid margarit...   \n",
       "2        3   16    1  opinion usuari reclam gran palad parec ser par...   \n",
       "3        2    9    2  curios form asemej sill mont ahi nombr icon ci...   \n",
       "4        2    9    1                  mejor limon gust com mund sos fri   \n",
       "...    ...  ...  ...                                                ...   \n",
       "7870     2   13    0  motiv estanci vin congres medic hosped lug ins...   \n",
       "7871     2   15    1  dificil revis castill apen pod camin sofoc cal...   \n",
       "7872     3    9    1  si vas mer pued perdert lug nuev sucursal ampl...   \n",
       "7873     2   18    0  imperd siti llev nombr conquist joy urbanasu a...   \n",
       "7874     2   13    0  festej dia amor amist remont restaur cafet par...   \n",
       "\n",
       "                                                 words1  \\\n",
       "0     [alojamos, casa, alquilada, ciudad, amurallada...   \n",
       "1     [comida, bien, especial, mejor, comida, mexcan...   \n",
       "2     [opinión, usuarios, reclaman, gran, paladar, p...   \n",
       "3     [curiosa, forma, asemeja, silla, montar, ahi, ...   \n",
       "4     [mejor, limonada, gusto, comida, mundo, sosa, ...   \n",
       "...                                                 ...   \n",
       "7870  [motivo, estancia, vine, congreso, medico, hos...   \n",
       "7871  [difícil, revisar, castillo, apenas, podíamos,...   \n",
       "7872  [si, vas, mérida, puedes, perderte, lugar, nue...   \n",
       "7873  [imperdible, sitio, lleva, nombre, conquistado...   \n",
       "7874  [festejando, dia, amor, amistad, remonta, rest...   \n",
       "\n",
       "                                                 words2  \\\n",
       "0     [aloj, cas, alquil, ciud, amurall, parec, tan,...   \n",
       "1     [com, bien, especial, mejor, com, mexc, unid, ...   \n",
       "2     [opinion, usuari, reclam, gran, palad, parec, ...   \n",
       "3     [curios, form, asemej, sill, mont, ahi, nombr,...   \n",
       "4             [mejor, limon, gust, com, mund, sos, fri]   \n",
       "...                                                 ...   \n",
       "7870  [motiv, estanci, vin, congres, medic, hosped, ...   \n",
       "7871  [dificil, revis, castill, apen, pod, camin, so...   \n",
       "7872  [si, vas, mer, pued, perdert, lug, nuev, sucur...   \n",
       "7873  [imperd, siti, llev, nombr, conquist, joy, urb...   \n",
       "7874  [festej, dia, amor, amist, remont, restaur, ca...   \n",
       "\n",
       "                                      lemmatized_review  \n",
       "0     yo alogir en uno casa alquilado en el ciudad a...  \n",
       "1     el comida estar bien , pero nada especial . yo...  \n",
       "2     en mi opinión , no ser uno como mucho usuario ...  \n",
       "3     este curioso forma que asemejar uno silla de m...  \n",
       "4     él mejor ser el limonado . yo gustar el comida...  \n",
       "...                                                 ...  \n",
       "7870  el motivo de mi estancia ser porque venir a un...  \n",
       "7871  ser difícil revisar el castillo porque apenas ...  \n",
       "7872  si ir a Mérida no poder perderte de este lugar...  \n",
       "7873  este imperdible sitio , que llevar el nombre d...  \n",
       "7874  Festejando Dia de el Amor y Amistad \\r\\n\\r\\n t...  \n",
       "\n",
       "[7875 rows x 10 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Unificación de las palabras\n",
    "molData=prepData.copy()\n",
    "molData['words'] = molData['words2'].apply(lambda x: ' '.join(map(str, x)))\n",
    "molData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Crea el test y el train set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(molData['words'], molData['Class'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión logistica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es un algoritmo de aprendizaje supervisado utilizado principalmente para problemas de clasificación binaria. Aunque su nombre incluye \"regresión\", en realidad es un modelo de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6300, 12892)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train_transformed  = vectorizer.fit_transform(X_train)\n",
    "X_test_transformed = vectorizer.transform(X_test)\n",
    "print(X_train_transformed .shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid= TfidfTransformer(use_idf=True, norm='l2', smooth_idf=True)\n",
    "X_train_transformed=tfid.fit_transform(X_train_transformed)\n",
    "X_test_transformed=tfid.transform(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4926984126984127\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train logistic regression model\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "logistic_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Predictions on test data\n",
    "y_pred = logistic_model.predict(X_test_transformed)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carlo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4768253968253968\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC(random_state=42)\n",
    "svm.fit(X_train_transformed, y_train)\n",
    "y_pred_svm_sample = svm.predict(X_test_transformed)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm_sample)\n",
    "print(\"Accuracy:\", accuracy_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se basa en la construcción de múltiples árboles de decisión durante el entrenamiento y combina sus predicciones para obtener una predicción más precisa y estable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.44825396825396824\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train Random Forest on the reduced dataset\n",
    "random_forest_sample = RandomForestClassifier(random_state=42)\n",
    "random_forest_sample.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Predict on the test set and calculate accuracy\n",
    "y_pred_rf_sample = random_forest_sample.predict(X_test_transformed)\n",
    "accuracy_rf_sample = accuracy_score(y_test, y_pred_rf_sample)\n",
    "\n",
    "print(\"Accuracy:\",accuracy_rf_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Son modelos de aprendizaje profundo inspirados en el funcionamiento del cerebro humano. Consisten en capas de nodos (neuronas) interconectados que procesan información y aprenden representaciones de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4419047619047619"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the neural network model\n",
    "# Let's use a simple architecture with two hidden layers of 100 neurons each\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=300, activation='relu', solver='adam', random_state=42)\n",
    "\n",
    "# Train the neural network on the reduced dataset\n",
    "mlp.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Predict on the test set and calculate accuracy\n",
    "y_pred_mlp = mlp.predict(X_test_transformed)\n",
    "accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "\n",
    "accuracy_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Son modelos de aprendizaje supervisado que pueden ser utilizados para problemas de clasificación y regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9485714285714286\n"
     ]
    }
   ],
   "source": [
    "#DecisionTree\n",
    "# Initialize the Decision Tree Regressor\n",
    "decision_tree_regressor = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Train the regressor on the reduced dataset\n",
    "decision_tree_regressor.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_dtr = decision_tree_regressor.predict(X_test_transformed)\n",
    "\n",
    "# For regression tasks, we typically use different metrics than accuracy, such as Mean Absolute Error (MAE)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, y_pred_dtr)\n",
    "\n",
    "### Menos es mejor\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creacion de predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regresión logística nos proporcionó la mayor precisión, por lo que decidimos utilizarla. Aunque los otros modelos nos dieron valores cercanos, optamos por recomendar el modelo de regresión logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba_estudiantes = pd.read_csv('particion_prueba_estudiantes.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba_estudiantes['words'] = prueba_estudiantes['Review'].apply(lambda x: ' '.join(map(str, x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prueba_transformed = vectorizer.transform(prueba_estudiantes['words'])\n",
    "X_prueba_transformed = tfid.transform(X_prueba_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prueba = logistic_model.predict(X_prueba_transformed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba_estudiantes['Prediction'] = y_pred_prueba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones guardadas en 'prueba_estudiantes_con_predicciones.csv'\n"
     ]
    }
   ],
   "source": [
    "prueba_estudiantes.to_csv('prueba_estudiantes_con_predicciones.csv', index=False)\n",
    "print(\"Predicciones guardadas en 'prueba_estudiantes_con_predicciones.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
