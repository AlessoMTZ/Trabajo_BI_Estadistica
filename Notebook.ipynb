{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\esteb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package cess_esp to\n",
      "[nltk_data]     C:\\Users\\esteb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cess_esp is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\esteb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\esteb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 19.9MB/s]                    \n",
      "2024-04-02 19:12:50 INFO: Downloaded file to C:\\Users\\esteb\\stanza_resources\\resources.json\n",
      "2024-04-02 19:12:50 INFO: Downloading default packages for language: es (Spanish) ...\n",
      "2024-04-02 19:12:52 INFO: File exists: C:\\Users\\esteb\\stanza_resources\\es\\default.zip\n",
      "2024-04-02 19:13:00 INFO: Finished downloading models and saved to C:\\Users\\esteb\\stanza_resources\n"
     ]
    }
   ],
   "source": [
    "## Importar las librerias\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from statistics import mode\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from langdetect import detect, LangDetectException\n",
    "from googletrans import Translator, LANGUAGES\n",
    "import string\n",
    "from num2words import num2words\n",
    "import re\n",
    "from nltk.corpus import cess_esp\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import stanza \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "\n",
    "## Descarga la información relevante de la libreria nltk\n",
    "nltk.download('punkt') # Tokenizador de palabras\n",
    "nltk.download('cess_esp') # Corpus en español\n",
    "nltk.download('stopwords') # Palabras vacias\n",
    "nltk.download('wordnet') # Sinonimos\n",
    "stanza.download('es')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importar el dataset\n",
    "filepath = 'tipo1_entrenamiento_estudiantes.csv'\n",
    "dataset = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define las contracciones del español\n",
    "contracciones = {\n",
    "    \"q\": \"que\",\n",
    "    \"d\": \"de\",\n",
    "    \"t\": \"te\",\n",
    "    \"m\": \"me\",\n",
    "    \"na\": \"nada\",\n",
    "    \"toy\": \"estoy\",\n",
    "    \"toy\": \"estoy\",\n",
    "    \"sta\": \"esta\",\n",
    "    \"tamos\": \"estamos\",\n",
    "    'verm': 'ver',\n",
    "    \"al\": \"a el\",\n",
    "    \"del\": \"de el\",\n",
    "    \"bn\": \"bien\",}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Da un listado de las palabras que no tienen mucha utilidad en español\n",
    "spanish_stopwords = set(stopwords.words('spanish'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entendimiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nos alojamos en una casa alquilada en la ciuda...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La comida está bien, pero nada especial. Yo te...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En mi opinión, no es una como muchos usuarios ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>esta curiosa forma que asemeja una silla de mo...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lo mejor era la limonada. Me gusto la comida d...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Class\n",
       "0  Nos alojamos en una casa alquilada en la ciuda...      4\n",
       "1  La comida está bien, pero nada especial. Yo te...      3\n",
       "2  En mi opinión, no es una como muchos usuarios ...      3\n",
       "3  esta curiosa forma que asemeja una silla de mo...      4\n",
       "4  Lo mejor era la limonada. Me gusto la comida d...      2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Muestra las primeras filas del dataset\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lenguaje\n",
       "es    7870\n",
       "en       4\n",
       "pt       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisa el idioma del dataset\n",
    "analisis= dataset.copy()\n",
    "\n",
    "# #Se define una función que detecta el idioma de un texto\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except LangDetectException:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# Apply the language detection function to the first few rows as a test\n",
    "analisis['lenguaje']=dataset['Review'].apply(detect_language)\n",
    "language_counts = analisis['lenguaje'].value_counts()\n",
    "language_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>lenguaje</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>A must when you're in Bogota and it's just in ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>First time in Colombia and the Hotel and servi...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3368</th>\n",
       "      <td>My expectations about this hotel were high due...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4835</th>\n",
       "      <td>This mercado is just like every mercado that I...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review lenguaje\n",
       "743   A must when you're in Bogota and it's just in ...       en\n",
       "1497  First time in Colombia and the Hotel and servi...       en\n",
       "3368  My expectations about this hotel were high due...       en\n",
       "4835  This mercado is just like every mercado that I...       en"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Muestra las filas en inglés\n",
    "\n",
    "# Filter the dataset for reviews estimated to be in English\n",
    "english_reviews = analisis[analisis['lenguaje'] == 'en']\n",
    "\n",
    "# Show the filtered rows\n",
    "english_reviews[['Review', 'lenguaje']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>lenguaje</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>Parada obrigatório em Havana para tomar o icôn...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review lenguaje\n",
       "1932  Parada obrigatório em Havana para tomar o icôn...       pt"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Muestra las filas en portugués\n",
    "\n",
    "# Filter the dataset for reviews estimated to be in English\n",
    "portuguese_reviews = analisis[analisis['lenguaje'] == 'pt']\n",
    "\n",
    "# Show the filtered rows\n",
    "portuguese_reviews[['Review', 'lenguaje']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7875 entries, 0 to 7874\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Review  7875 non-null   object\n",
      " 1   Class   7875 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 123.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Revisa la información del dataset\n",
    "dataset.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nótese que no existe ningún dato faltante, también que todos los elementos de la clase son del tipo entero, por lo que no hay errores en la variable numérica. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "5    2350\n",
       "4    1971\n",
       "3    1568\n",
       "2    1173\n",
       "1     813\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribución de la columna Class\n",
    "dataset['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nótese que la distribución de la información respecto a la columna clase está desbalanceada, entonces hay más datos clasificados en las clases más altas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Class</th>\n",
       "      <th>lenguaje</th>\n",
       "      <th>NumPalabras</th>\n",
       "      <th>Moda</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nos alojamos en una casa alquilada en la ciuda...</td>\n",
       "      <td>4</td>\n",
       "      <td>es</td>\n",
       "      <td>416</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La comida está bien, pero nada especial. Yo te...</td>\n",
       "      <td>3</td>\n",
       "      <td>es</td>\n",
       "      <td>263</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En mi opinión, no es una como muchos usuarios ...</td>\n",
       "      <td>3</td>\n",
       "      <td>es</td>\n",
       "      <td>612</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>esta curiosa forma que asemeja una silla de mo...</td>\n",
       "      <td>4</td>\n",
       "      <td>es</td>\n",
       "      <td>180</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lo mejor era la limonada. Me gusto la comida d...</td>\n",
       "      <td>2</td>\n",
       "      <td>es</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7870</th>\n",
       "      <td>El motivo de mi estancia fue porque vine a un ...</td>\n",
       "      <td>3</td>\n",
       "      <td>es</td>\n",
       "      <td>624</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7871</th>\n",
       "      <td>Es difícil revisar el castillo porque apenas p...</td>\n",
       "      <td>3</td>\n",
       "      <td>es</td>\n",
       "      <td>609</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7872</th>\n",
       "      <td>Si vas a Mérida no puedes perderte de este lug...</td>\n",
       "      <td>5</td>\n",
       "      <td>es</td>\n",
       "      <td>168</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7873</th>\n",
       "      <td>Este imperdible sitio, que lleva el nombre del...</td>\n",
       "      <td>5</td>\n",
       "      <td>es</td>\n",
       "      <td>424</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7874</th>\n",
       "      <td>Festejando Dia del Amor y Amistad\\r\\n\\r\\nTe re...</td>\n",
       "      <td>3</td>\n",
       "      <td>es</td>\n",
       "      <td>265</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7875 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review  Class lenguaje  \\\n",
       "0     Nos alojamos en una casa alquilada en la ciuda...      4       es   \n",
       "1     La comida está bien, pero nada especial. Yo te...      3       es   \n",
       "2     En mi opinión, no es una como muchos usuarios ...      3       es   \n",
       "3     esta curiosa forma que asemeja una silla de mo...      4       es   \n",
       "4     Lo mejor era la limonada. Me gusto la comida d...      2       es   \n",
       "...                                                 ...    ...      ...   \n",
       "7870  El motivo de mi estancia fue porque vine a un ...      3       es   \n",
       "7871  Es difícil revisar el castillo porque apenas p...      3       es   \n",
       "7872  Si vas a Mérida no puedes perderte de este lug...      5       es   \n",
       "7873  Este imperdible sitio, que lleva el nombre del...      5       es   \n",
       "7874  Festejando Dia del Amor y Amistad\\r\\n\\r\\nTe re...      3       es   \n",
       "\n",
       "      NumPalabras  Moda  Max  Min  \n",
       "0             416     2   13    1  \n",
       "1             263     2   14    1  \n",
       "2             612     3   16    1  \n",
       "3             180     2    9    2  \n",
       "4              88     2    9    1  \n",
       "...           ...   ...  ...  ...  \n",
       "7870          624     2   13    0  \n",
       "7871          609     2   15    1  \n",
       "7872          168     3    9    1  \n",
       "7873          424     2   18    0  \n",
       "7874          265     2   13    0  \n",
       "\n",
       "[7875 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisa la información de las palabras en lo que respecta a la variable categórica.\n",
    "\n",
    "\n",
    "analisis['NumPalabras']= [len(word) for word in dataset['Review']]\n",
    "analisis['Moda'] = analisis['Review'].apply(lambda review: mode([len(word) for word in review.split()]) if review else None)\n",
    "analisis['Max'] = [max([len(word) for word in review.split(' ')]) for review in analisis['Review']]\n",
    "analisis['Min'] = [min([len(word) for word in review.split(' ')]) for review in analisis['Review']]\n",
    "\n",
    "analisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la preparación de los datos se van a realizar los siguientes pasos:\n",
    "* Traducción de datos \n",
    "* Limpieza de datos\n",
    "* Tokenización\n",
    "* Normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un dataset diferente para hacer la preparación de los datos\n",
    "prepData= analisis.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traducción de los datos ajenos al idioma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Review lenguaje\n",
      "1932  Parada obligatoria en La Habana para tomar la ...       pt\n",
      "                                                 Review lenguaje\n",
      "743   Una visita obligada cuando estás en Bogotá y e...       en\n",
      "1497  La primera vez en Colombia y el hotel y el ser...       en\n",
      "3368  Mis expectativas sobre este hotel fueron altas...       en\n",
      "4835  Este mercado es como todos los mercados que he...       en\n"
     ]
    }
   ],
   "source": [
    "#Se traducen los idiomas ajenos al lenguaje español\n",
    "translator = Translator()\n",
    "def translate_to_spanish(text):\n",
    "    # Detecta el idioma del texto\n",
    "    detected = translator.detect(text)\n",
    "    \n",
    "    # Verifica si el texto ya está en español\n",
    "    if detected.lang == 'es':\n",
    "        return text\n",
    "    \n",
    "    # Si el texto no está en español, lo traduce al español\n",
    "    translated = translator.translate(text, src=detected.lang, dest='es')\n",
    "    return translated.text\n",
    "if 'lenguaje' in prepData.columns:\n",
    "    prepData.loc[prepData['lenguaje'] == 'pt', 'Review'] = prepData.loc[prepData['lenguaje'] == 'pt', 'Review'].apply(lambda x: translate_to_spanish(x))\n",
    "    prepData.loc[prepData['lenguaje'] == 'en', 'Review'] = prepData.loc[prepData['lenguaje'] == 'en', 'Review'].apply(lambda x: translate_to_spanish(x))\n",
    "    portuguese_reviews = prepData[prepData['lenguaje'] == 'pt']\n",
    "    portuguese_reviews[['Review', 'lenguaje']]\n",
    "    #Verifica que se haya traducido el portugués\n",
    "    print(portuguese_reviews[['Review', 'lenguaje']])\n",
    "    english_reviews = prepData[prepData['lenguaje'] == 'en']\n",
    "    #Verifica que se haya traducido el inglés\n",
    "    print(english_reviews[['Review', 'lenguaje']])\n",
    "    prepData.drop('lenguaje', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la limpieza de datos se va a garantizar que :\n",
    "* Se deja todo en minuscula\n",
    "* Remover carácteres no deseados\n",
    "* Remover puntuación\n",
    "* Manejar valores numéricos\n",
    "* Remover palabras que no tienen un gran sentimiento (StopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se deja todo en minuscula\n",
    "def lower_case_words(tokenized_words):\n",
    "    \"\"\"Convert all words in a list to lowercase.\"\"\"\n",
    "    # Use a list comprehension to convert each word in the list to lowercase\n",
    "    lowercased_words = [word.lower() for word in tokenized_words]\n",
    "    \n",
    "    return lowercased_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimina todos los elementos que no son necesarios y no se buscan utilizar\n",
    "\n",
    "def remove_unwanted_characters_from_tokens(tokenized_words):\n",
    "    \"\"\"Remove unwanted non-ASCII characters from a list of tokenized words, retaining Spanish characters.\"\"\"\n",
    "    # Include the Spanish alphabet, both lowercase and uppercase, digits, and common punctuation\n",
    "    allowed_characters = set(\"abcdefghijklmnopqrstuvwxyzáéíóúüñABCDEFGHIJKLMNOPQRSTUVWXYZÁÉÍÓÚÜÑ \" + string.digits + string.punctuation)\n",
    "    \n",
    "    # Initialize an empty list to hold the cleaned words\n",
    "    new_words = []\n",
    "    \n",
    "    # Iterate over each word in the list of tokenized words\n",
    "    for word in tokenized_words:\n",
    "        # Filter each word to include only allowed characters\n",
    "        cleaned_word = ''.join(char for char in word if char in allowed_characters)\n",
    "        # Append the cleaned word to the new list\n",
    "        if cleaned_word == word:\n",
    "            # If they are the same, it means the word contains only allowed characters, so append it to the list\n",
    "            new_words.append(cleaned_word)\n",
    "    \n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remueve la punctuación dentro de cada palabra\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words, with explicit support for Unicode characters.\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word is not None:\n",
    "            # Use \\w for word characters, \\s for whitespace, and ensure Unicode support\n",
    "            new_word = re.sub(r'[^\\w\\s]', '', word, flags=re.UNICODE)\n",
    "            if new_word != '':\n",
    "                new_words.append(new_word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierte los números a palabras\n",
    "def convert_numbers_to_words(words):\n",
    "    \"\"\"Convert all numbers in a text to their word representation in the specified language.\"\"\"\n",
    "    \n",
    "    # Convert each word\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            word= float(word)\n",
    "            # Convert the numerical word to its word representation\n",
    "            word_in_text = num2words(word, lang='es')\n",
    "            new_words.append(word_in_text)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remueve las stopwords o palabras sin mucha prioridad en el analisis\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    # Filter out any words that are in the list of stop words\n",
    "    filtered_words = [word for word in words if word not in spanish_stopwords]\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(words):\n",
    "    \"\"\"Preprocess a list of tokenized words\"\"\"\n",
    "    # Remove unwanted characters\n",
    "    words = remove_unwanted_characters_from_tokens(words)\n",
    "    # Convert to lowercase\n",
    "    words = lower_case_words(words)\n",
    "    # Convert numbers to words\n",
    "    words = convert_numbers_to_words(words)\n",
    "    # Remove punctuation\n",
    "    words = remove_punctuation(words)\n",
    "    # Remove stop words\n",
    "    words = remove_stopwords(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Class</th>\n",
       "      <th>NumPalabras</th>\n",
       "      <th>Moda</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nos alojamos en una casa alquilada en la ciuda...</td>\n",
       "      <td>4</td>\n",
       "      <td>416</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La comida está bien, pero nada especial. Yo te...</td>\n",
       "      <td>3</td>\n",
       "      <td>263</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En mi opinión, no es una como muchos usuarios ...</td>\n",
       "      <td>3</td>\n",
       "      <td>612</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>esta curiosa forma que asemeja una silla de mo...</td>\n",
       "      <td>4</td>\n",
       "      <td>180</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lo mejor era la limonada. Me gusto la comida d...</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7870</th>\n",
       "      <td>El motivo de mi estancia fue porque vine a un ...</td>\n",
       "      <td>3</td>\n",
       "      <td>624</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7871</th>\n",
       "      <td>Es difícil revisar el castillo porque apenas p...</td>\n",
       "      <td>3</td>\n",
       "      <td>609</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7872</th>\n",
       "      <td>Si vas a Mérida no puedes perderte de este lug...</td>\n",
       "      <td>5</td>\n",
       "      <td>168</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7873</th>\n",
       "      <td>Este imperdible sitio, que lleva el nombre de ...</td>\n",
       "      <td>5</td>\n",
       "      <td>424</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7874</th>\n",
       "      <td>Festejando Dia de el Amor y Amistad\\r\\n\\r\\nTe ...</td>\n",
       "      <td>3</td>\n",
       "      <td>265</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7875 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review  Class  NumPalabras  \\\n",
       "0     Nos alojamos en una casa alquilada en la ciuda...      4          416   \n",
       "1     La comida está bien, pero nada especial. Yo te...      3          263   \n",
       "2     En mi opinión, no es una como muchos usuarios ...      3          612   \n",
       "3     esta curiosa forma que asemeja una silla de mo...      4          180   \n",
       "4     Lo mejor era la limonada. Me gusto la comida d...      2           88   \n",
       "...                                                 ...    ...          ...   \n",
       "7870  El motivo de mi estancia fue porque vine a un ...      3          624   \n",
       "7871  Es difícil revisar el castillo porque apenas p...      3          609   \n",
       "7872  Si vas a Mérida no puedes perderte de este lug...      5          168   \n",
       "7873  Este imperdible sitio, que lleva el nombre de ...      5          424   \n",
       "7874  Festejando Dia de el Amor y Amistad\\r\\n\\r\\nTe ...      3          265   \n",
       "\n",
       "      Moda  Max  Min  \n",
       "0        2   13    1  \n",
       "1        2   14    1  \n",
       "2        3   16    1  \n",
       "3        2    9    2  \n",
       "4        2    9    1  \n",
       "...    ...  ...  ...  \n",
       "7870     2   13    0  \n",
       "7871     2   15    1  \n",
       "7872     3    9    1  \n",
       "7873     2   18    0  \n",
       "7874     2   13    0  \n",
       "\n",
       "[7875 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Expandir las contracciones y reemplazarlas\n",
    "def expandir_contracciones(texto, contracciones_dict):\n",
    "    \"\"\"\n",
    "    Expande las contracciones encontradas en el texto basándose en un diccionario de contracciones.\n",
    "    \"\"\"\n",
    "    # Asegurarse de que la expresión regular coincide solo con palabras completas. \n",
    "    # \\b es un límite de palabra, lo que ayuda a coincidir solo palabras completas.\n",
    "    contracciones_re = re.compile(r'\\b(%s)\\b' % '|'.join(map(re.escape, contracciones_dict.keys())))\n",
    "\n",
    "    def reemplazo(match):\n",
    "        return contracciones_dict[match.group(0)]\n",
    "\n",
    "    texto_expandido = contracciones_re.sub(reemplazo, texto)\n",
    "    \n",
    "    return texto_expandido\n",
    "\n",
    "prepData['Review'] = prepData['Review'].apply(expandir_contracciones, contracciones_dict=contracciones)\n",
    "prepData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Class</th>\n",
       "      <th>NumPalabras</th>\n",
       "      <th>Moda</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>words</th>\n",
       "      <th>words1</th>\n",
       "      <th>words2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nos alojamos en una casa alquilada en la ciuda...</td>\n",
       "      <td>4</td>\n",
       "      <td>416</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>[Nos, alojamos, en, una, casa, alquilada, en, ...</td>\n",
       "      <td>[alojamos, casa, alquilada, ciudad, amurallada...</td>\n",
       "      <td>[aloj, cas, alquil, ciud, amurall, parec, tan,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La comida está bien, pero nada especial. Yo te...</td>\n",
       "      <td>3</td>\n",
       "      <td>263</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>[La, comida, está, bien, ,, pero, nada, especi...</td>\n",
       "      <td>[comida, bien, especial, mejor, comida, mexcan...</td>\n",
       "      <td>[com, bien, especial, mejor, com, mexc, unid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En mi opinión, no es una como muchos usuarios ...</td>\n",
       "      <td>3</td>\n",
       "      <td>612</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>[En, mi, opinión, ,, no, es, una, como, muchos...</td>\n",
       "      <td>[opinión, usuarios, reclaman, gran, paladar, p...</td>\n",
       "      <td>[opinion, usuari, reclam, gran, palad, parec, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>esta curiosa forma que asemeja una silla de mo...</td>\n",
       "      <td>4</td>\n",
       "      <td>180</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>[esta, curiosa, forma, que, asemeja, una, sill...</td>\n",
       "      <td>[curiosa, forma, asemeja, silla, montar, ahi, ...</td>\n",
       "      <td>[curios, form, asemej, sill, mont, ahi, nombr,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lo mejor era la limonada. Me gusto la comida d...</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[Lo, mejor, era, la, limonada, ., Me, gusto, l...</td>\n",
       "      <td>[mejor, limonada, gusto, comida, mundo, sosa, ...</td>\n",
       "      <td>[mejor, limon, gust, com, mund, sos, fri]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Class  NumPalabras  \\\n",
       "0  Nos alojamos en una casa alquilada en la ciuda...      4          416   \n",
       "1  La comida está bien, pero nada especial. Yo te...      3          263   \n",
       "2  En mi opinión, no es una como muchos usuarios ...      3          612   \n",
       "3  esta curiosa forma que asemeja una silla de mo...      4          180   \n",
       "4  Lo mejor era la limonada. Me gusto la comida d...      2           88   \n",
       "\n",
       "   Moda  Max  Min                                              words  \\\n",
       "0     2   13    1  [Nos, alojamos, en, una, casa, alquilada, en, ...   \n",
       "1     2   14    1  [La, comida, está, bien, ,, pero, nada, especi...   \n",
       "2     3   16    1  [En, mi, opinión, ,, no, es, una, como, muchos...   \n",
       "3     2    9    2  [esta, curiosa, forma, que, asemeja, una, sill...   \n",
       "4     2    9    1  [Lo, mejor, era, la, limonada, ., Me, gusto, l...   \n",
       "\n",
       "                                              words1  \\\n",
       "0  [alojamos, casa, alquilada, ciudad, amurallada...   \n",
       "1  [comida, bien, especial, mejor, comida, mexcan...   \n",
       "2  [opinión, usuarios, reclaman, gran, paladar, p...   \n",
       "3  [curiosa, forma, asemeja, silla, montar, ahi, ...   \n",
       "4  [mejor, limonada, gusto, comida, mundo, sosa, ...   \n",
       "\n",
       "                                              words2  \n",
       "0  [aloj, cas, alquil, ciud, amurall, parec, tan,...  \n",
       "1  [com, bien, especial, mejor, com, mexc, unid, ...  \n",
       "2  [opinion, usuari, reclam, gran, palad, parec, ...  \n",
       "3  [curios, form, asemej, sill, mont, ahi, nombr,...  \n",
       "4          [mejor, limon, gust, com, mund, sos, fri]  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenizar\n",
    "def nltk_spanish_tokenizer(text):\n",
    "    return word_tokenize(text, language='spanish')\n",
    "prepData['words'] = prepData['Review'].apply(lambda x: word_tokenize(x, language='spanish'))\n",
    "prepData.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Nos, alojamos, en, una, casa, alquilada, en, ...\n",
       "1       [La, comida, está, bien, ,, pero, nada, especi...\n",
       "2       [En, mi, opinión, ,, no, es, una, como, muchos...\n",
       "3       [esta, curiosa, forma, que, asemeja, una, sill...\n",
       "4       [Lo, mejor, era, la, limonada, ., Me, gusto, l...\n",
       "                              ...                        \n",
       "7870    [El, motivo, de, mi, estancia, fue, porque, vi...\n",
       "7871    [Es, difícil, revisar, el, castillo, porque, a...\n",
       "7872    [Si, vas, a, Mérida, no, puedes, perderte, de,...\n",
       "7873    [Este, imperdible, sitio, ,, que, lleva, el, n...\n",
       "7874    [Festejando, Dia, de, el, Amor, y, Amistad, Te...\n",
       "Name: words, Length: 7875, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Elimina los valores nulos del conjunto de palabras\n",
    "prepData['words'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7875 entries, 0 to 7874\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Review       7875 non-null   object\n",
      " 1   Class        7875 non-null   int64 \n",
      " 2   NumPalabras  7875 non-null   int64 \n",
      " 3   Moda         7875 non-null   int64 \n",
      " 4   Max          7875 non-null   int64 \n",
      " 5   Min          7875 non-null   int64 \n",
      " 6   words        7875 non-null   object\n",
      " 7   words1       7875 non-null   object\n",
      " 8   words2       7875 non-null   object\n",
      "dtypes: int64(5), object(4)\n",
      "memory usage: 553.8+ KB\n"
     ]
    }
   ],
   "source": [
    "prepData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Class</th>\n",
       "      <th>NumPalabras</th>\n",
       "      <th>Moda</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>words</th>\n",
       "      <th>words1</th>\n",
       "      <th>words2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nos alojamos en una casa alquilada en la ciuda...</td>\n",
       "      <td>4</td>\n",
       "      <td>416</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>[Nos, alojamos, en, una, casa, alquilada, en, ...</td>\n",
       "      <td>[alojamos, casa, alquilada, ciudad, amurallada...</td>\n",
       "      <td>[aloj, cas, alquil, ciud, amurall, parec, tan,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La comida está bien, pero nada especial. Yo te...</td>\n",
       "      <td>3</td>\n",
       "      <td>263</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>[La, comida, está, bien, ,, pero, nada, especi...</td>\n",
       "      <td>[comida, bien, especial, mejor, comida, mexcan...</td>\n",
       "      <td>[com, bien, especial, mejor, com, mexc, unid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En mi opinión, no es una como muchos usuarios ...</td>\n",
       "      <td>3</td>\n",
       "      <td>612</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>[En, mi, opinión, ,, no, es, una, como, muchos...</td>\n",
       "      <td>[opinión, usuarios, reclaman, gran, paladar, p...</td>\n",
       "      <td>[opinion, usuari, reclam, gran, palad, parec, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>esta curiosa forma que asemeja una silla de mo...</td>\n",
       "      <td>4</td>\n",
       "      <td>180</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>[esta, curiosa, forma, que, asemeja, una, sill...</td>\n",
       "      <td>[curiosa, forma, asemeja, silla, montar, ahi, ...</td>\n",
       "      <td>[curios, form, asemej, sill, mont, ahi, nombr,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lo mejor era la limonada. Me gusto la comida d...</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[Lo, mejor, era, la, limonada, ., Me, gusto, l...</td>\n",
       "      <td>[mejor, limonada, gusto, comida, mundo, sosa, ...</td>\n",
       "      <td>[mejor, limon, gust, com, mund, sos, fri]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Class  NumPalabras  \\\n",
       "0  Nos alojamos en una casa alquilada en la ciuda...      4          416   \n",
       "1  La comida está bien, pero nada especial. Yo te...      3          263   \n",
       "2  En mi opinión, no es una como muchos usuarios ...      3          612   \n",
       "3  esta curiosa forma que asemeja una silla de mo...      4          180   \n",
       "4  Lo mejor era la limonada. Me gusto la comida d...      2           88   \n",
       "\n",
       "   Moda  Max  Min                                              words  \\\n",
       "0     2   13    1  [Nos, alojamos, en, una, casa, alquilada, en, ...   \n",
       "1     2   14    1  [La, comida, está, bien, ,, pero, nada, especi...   \n",
       "2     3   16    1  [En, mi, opinión, ,, no, es, una, como, muchos...   \n",
       "3     2    9    2  [esta, curiosa, forma, que, asemeja, una, sill...   \n",
       "4     2    9    1  [Lo, mejor, era, la, limonada, ., Me, gusto, l...   \n",
       "\n",
       "                                              words1  \\\n",
       "0  [alojamos, casa, alquilada, ciudad, amurallada...   \n",
       "1  [comida, bien, especial, mejor, comida, mexcan...   \n",
       "2  [opinión, usuarios, reclaman, gran, paladar, p...   \n",
       "3  [curiosa, forma, asemeja, silla, montar, ahi, ...   \n",
       "4  [mejor, limonada, gusto, comida, mundo, sosa, ...   \n",
       "\n",
       "                                              words2  \n",
       "0  [aloj, cas, alquil, ciud, amurall, parec, tan,...  \n",
       "1  [com, bien, especial, mejor, com, mexc, unid, ...  \n",
       "2  [opinion, usuari, reclam, gran, palad, parec, ...  \n",
       "3  [curios, form, asemej, sill, mont, ahi, nombr,...  \n",
       "4          [mejor, limon, gust, com, mund, sos, fri]  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aplica el procesamiento básico\n",
    "prepData['words1']=prepData['words'].apply(preprocessing)\n",
    "prepData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemmer\n",
    "\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    # Stem each word in the list of words\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return stemmed_words\n",
    "\n",
    "#This is just for trying the stemmer\n",
    "def stemExample(text):\n",
    "   return [stemmer.stem(word) for word in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Class</th>\n",
       "      <th>NumPalabras</th>\n",
       "      <th>Moda</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>words</th>\n",
       "      <th>words1</th>\n",
       "      <th>words2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nos alojamos en una casa alquilada en la ciuda...</td>\n",
       "      <td>4</td>\n",
       "      <td>416</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>[Nos, alojamos, en, una, casa, alquilada, en, ...</td>\n",
       "      <td>[alojamos, casa, alquilada, ciudad, amurallada...</td>\n",
       "      <td>[aloj, cas, alquil, ciud, amurall, parec, tan,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La comida está bien, pero nada especial. Yo te...</td>\n",
       "      <td>3</td>\n",
       "      <td>263</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>[La, comida, está, bien, ,, pero, nada, especi...</td>\n",
       "      <td>[comida, bien, especial, mejor, comida, mexcan...</td>\n",
       "      <td>[com, bien, especial, mejor, com, mexc, unid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En mi opinión, no es una como muchos usuarios ...</td>\n",
       "      <td>3</td>\n",
       "      <td>612</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>[En, mi, opinión, ,, no, es, una, como, muchos...</td>\n",
       "      <td>[opinión, usuarios, reclaman, gran, paladar, p...</td>\n",
       "      <td>[opinion, usuari, reclam, gran, palad, parec, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>esta curiosa forma que asemeja una silla de mo...</td>\n",
       "      <td>4</td>\n",
       "      <td>180</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>[esta, curiosa, forma, que, asemeja, una, sill...</td>\n",
       "      <td>[curiosa, forma, asemeja, silla, montar, ahi, ...</td>\n",
       "      <td>[curios, form, asemej, sill, mont, ahi, nombr,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lo mejor era la limonada. Me gusto la comida d...</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[Lo, mejor, era, la, limonada, ., Me, gusto, l...</td>\n",
       "      <td>[mejor, limonada, gusto, comida, mundo, sosa, ...</td>\n",
       "      <td>[mejor, limon, gust, com, mund, sos, fri]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Class  NumPalabras  \\\n",
       "0  Nos alojamos en una casa alquilada en la ciuda...      4          416   \n",
       "1  La comida está bien, pero nada especial. Yo te...      3          263   \n",
       "2  En mi opinión, no es una como muchos usuarios ...      3          612   \n",
       "3  esta curiosa forma que asemeja una silla de mo...      4          180   \n",
       "4  Lo mejor era la limonada. Me gusto la comida d...      2           88   \n",
       "\n",
       "   Moda  Max  Min                                              words  \\\n",
       "0     2   13    1  [Nos, alojamos, en, una, casa, alquilada, en, ...   \n",
       "1     2   14    1  [La, comida, está, bien, ,, pero, nada, especi...   \n",
       "2     3   16    1  [En, mi, opinión, ,, no, es, una, como, muchos...   \n",
       "3     2    9    2  [esta, curiosa, forma, que, asemeja, una, sill...   \n",
       "4     2    9    1  [Lo, mejor, era, la, limonada, ., Me, gusto, l...   \n",
       "\n",
       "                                              words1  \\\n",
       "0  [alojamos, casa, alquilada, ciudad, amurallada...   \n",
       "1  [comida, bien, especial, mejor, comida, mexcan...   \n",
       "2  [opinión, usuarios, reclaman, gran, paladar, p...   \n",
       "3  [curiosa, forma, asemeja, silla, montar, ahi, ...   \n",
       "4  [mejor, limonada, gusto, comida, mundo, sosa, ...   \n",
       "\n",
       "                                              words2  \n",
       "0  [aloj, cas, alquil, ciud, amurall, parec, tan,...  \n",
       "1  [com, bien, especial, mejor, com, mexc, unid, ...  \n",
       "2  [opinion, usuari, reclam, gran, palad, parec, ...  \n",
       "3  [curios, form, asemej, sill, mont, ahi, nombr,...  \n",
       "4          [mejor, limon, gust, com, mund, sos, fri]  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Apply Stemmer to the words\n",
    "prepData['words2'] = prepData['words1'].apply(stem_words)\n",
    "prepData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Lemmatization\n",
    "\n",
    "# # Initialize the Spanish pipeline\n",
    "# nlp = stanza.Pipeline(lang='es', processors='tokenize,mwt,pos,lemma')\n",
    "\n",
    "# def lemmatize_words(words):\n",
    "#     \"\"\"Lemmatize a list of words in Spanish\"\"\"\n",
    "#     # Join words into a single string as Stanza processes text inputs\n",
    "#     text = ' '.join(words)\n",
    "    \n",
    "#     # Process the text\n",
    "#     doc = nlp(text)\n",
    "    \n",
    "#     # Extract lemmas for each word\n",
    "#     lemmatized_words = [word.lemma for sentence in doc.sentences for word in sentence.words]\n",
    "#     return lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Apply lemmatization to the words\n",
    "# prepData['words3'] = prepData['words1'].apply(lemmatize_words)\n",
    "# prepData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Class</th>\n",
       "      <th>NumPalabras</th>\n",
       "      <th>Moda</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>words</th>\n",
       "      <th>words1</th>\n",
       "      <th>words2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nos alojamos en una casa alquilada en la ciuda...</td>\n",
       "      <td>4</td>\n",
       "      <td>416</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>[Nos, alojamos, en, una, casa, alquilada, en, ...</td>\n",
       "      <td>[alojamos, casa, alquilada, ciudad, amurallada...</td>\n",
       "      <td>[aloj, cas, alquil, ciud, amurall, parec, tan,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La comida está bien, pero nada especial. Yo te...</td>\n",
       "      <td>3</td>\n",
       "      <td>263</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>[La, comida, está, bien, ,, pero, nada, especi...</td>\n",
       "      <td>[comida, bien, especial, mejor, comida, mexcan...</td>\n",
       "      <td>[com, bien, especial, mejor, com, mexc, unid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En mi opinión, no es una como muchos usuarios ...</td>\n",
       "      <td>3</td>\n",
       "      <td>612</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>[En, mi, opinión, ,, no, es, una, como, muchos...</td>\n",
       "      <td>[opinión, usuarios, reclaman, gran, paladar, p...</td>\n",
       "      <td>[opinion, usuari, reclam, gran, palad, parec, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>esta curiosa forma que asemeja una silla de mo...</td>\n",
       "      <td>4</td>\n",
       "      <td>180</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>[esta, curiosa, forma, que, asemeja, una, sill...</td>\n",
       "      <td>[curiosa, forma, asemeja, silla, montar, ahi, ...</td>\n",
       "      <td>[curios, form, asemej, sill, mont, ahi, nombr,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lo mejor era la limonada. Me gusto la comida d...</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[Lo, mejor, era, la, limonada, ., Me, gusto, l...</td>\n",
       "      <td>[mejor, limonada, gusto, comida, mundo, sosa, ...</td>\n",
       "      <td>[mejor, limon, gust, com, mund, sos, fri]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7870</th>\n",
       "      <td>El motivo de mi estancia fue porque vine a un ...</td>\n",
       "      <td>3</td>\n",
       "      <td>624</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>[El, motivo, de, mi, estancia, fue, porque, vi...</td>\n",
       "      <td>[motivo, estancia, vine, congreso, medico, hos...</td>\n",
       "      <td>[motiv, estanci, vin, congres, medic, hosped, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7871</th>\n",
       "      <td>Es difícil revisar el castillo porque apenas p...</td>\n",
       "      <td>3</td>\n",
       "      <td>609</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>[Es, difícil, revisar, el, castillo, porque, a...</td>\n",
       "      <td>[difícil, revisar, castillo, apenas, podíamos,...</td>\n",
       "      <td>[dificil, revis, castill, apen, pod, camin, so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7872</th>\n",
       "      <td>Si vas a Mérida no puedes perderte de este lug...</td>\n",
       "      <td>5</td>\n",
       "      <td>168</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[Si, vas, a, Mérida, no, puedes, perderte, de,...</td>\n",
       "      <td>[si, vas, mérida, puedes, perderte, lugar, nue...</td>\n",
       "      <td>[si, vas, mer, pued, perdert, lug, nuev, sucur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7873</th>\n",
       "      <td>Este imperdible sitio, que lleva el nombre de ...</td>\n",
       "      <td>5</td>\n",
       "      <td>424</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>[Este, imperdible, sitio, ,, que, lleva, el, n...</td>\n",
       "      <td>[imperdible, sitio, lleva, nombre, conquistado...</td>\n",
       "      <td>[imperd, siti, llev, nombr, conquist, joy, urb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7874</th>\n",
       "      <td>Festejando Dia de el Amor y Amistad\\r\\n\\r\\nTe ...</td>\n",
       "      <td>3</td>\n",
       "      <td>265</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>[Festejando, Dia, de, el, Amor, y, Amistad, Te...</td>\n",
       "      <td>[festejando, dia, amor, amistad, remonta, rest...</td>\n",
       "      <td>[festej, dia, amor, amist, remont, restaur, ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7875 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review  Class  NumPalabras  \\\n",
       "0     Nos alojamos en una casa alquilada en la ciuda...      4          416   \n",
       "1     La comida está bien, pero nada especial. Yo te...      3          263   \n",
       "2     En mi opinión, no es una como muchos usuarios ...      3          612   \n",
       "3     esta curiosa forma que asemeja una silla de mo...      4          180   \n",
       "4     Lo mejor era la limonada. Me gusto la comida d...      2           88   \n",
       "...                                                 ...    ...          ...   \n",
       "7870  El motivo de mi estancia fue porque vine a un ...      3          624   \n",
       "7871  Es difícil revisar el castillo porque apenas p...      3          609   \n",
       "7872  Si vas a Mérida no puedes perderte de este lug...      5          168   \n",
       "7873  Este imperdible sitio, que lleva el nombre de ...      5          424   \n",
       "7874  Festejando Dia de el Amor y Amistad\\r\\n\\r\\nTe ...      3          265   \n",
       "\n",
       "      Moda  Max  Min                                              words  \\\n",
       "0        2   13    1  [Nos, alojamos, en, una, casa, alquilada, en, ...   \n",
       "1        2   14    1  [La, comida, está, bien, ,, pero, nada, especi...   \n",
       "2        3   16    1  [En, mi, opinión, ,, no, es, una, como, muchos...   \n",
       "3        2    9    2  [esta, curiosa, forma, que, asemeja, una, sill...   \n",
       "4        2    9    1  [Lo, mejor, era, la, limonada, ., Me, gusto, l...   \n",
       "...    ...  ...  ...                                                ...   \n",
       "7870     2   13    0  [El, motivo, de, mi, estancia, fue, porque, vi...   \n",
       "7871     2   15    1  [Es, difícil, revisar, el, castillo, porque, a...   \n",
       "7872     3    9    1  [Si, vas, a, Mérida, no, puedes, perderte, de,...   \n",
       "7873     2   18    0  [Este, imperdible, sitio, ,, que, lleva, el, n...   \n",
       "7874     2   13    0  [Festejando, Dia, de, el, Amor, y, Amistad, Te...   \n",
       "\n",
       "                                                 words1  \\\n",
       "0     [alojamos, casa, alquilada, ciudad, amurallada...   \n",
       "1     [comida, bien, especial, mejor, comida, mexcan...   \n",
       "2     [opinión, usuarios, reclaman, gran, paladar, p...   \n",
       "3     [curiosa, forma, asemeja, silla, montar, ahi, ...   \n",
       "4     [mejor, limonada, gusto, comida, mundo, sosa, ...   \n",
       "...                                                 ...   \n",
       "7870  [motivo, estancia, vine, congreso, medico, hos...   \n",
       "7871  [difícil, revisar, castillo, apenas, podíamos,...   \n",
       "7872  [si, vas, mérida, puedes, perderte, lugar, nue...   \n",
       "7873  [imperdible, sitio, lleva, nombre, conquistado...   \n",
       "7874  [festejando, dia, amor, amistad, remonta, rest...   \n",
       "\n",
       "                                                 words2  \n",
       "0     [aloj, cas, alquil, ciud, amurall, parec, tan,...  \n",
       "1     [com, bien, especial, mejor, com, mexc, unid, ...  \n",
       "2     [opinion, usuari, reclam, gran, palad, parec, ...  \n",
       "3     [curios, form, asemej, sill, mont, ahi, nombr,...  \n",
       "4             [mejor, limon, gust, com, mund, sos, fri]  \n",
       "...                                                 ...  \n",
       "7870  [motiv, estanci, vin, congres, medic, hosped, ...  \n",
       "7871  [dificil, revis, castill, apen, pod, camin, so...  \n",
       "7872  [si, vas, mer, pued, perdert, lug, nuev, sucur...  \n",
       "7873  [imperd, siti, llev, nombr, conquist, joy, urb...  \n",
       "7874  [festej, dia, amor, amist, remont, restaur, ca...  \n",
       "\n",
       "[7875 rows x 9 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación e implementación de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Class</th>\n",
       "      <th>NumPalabras</th>\n",
       "      <th>Moda</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>words</th>\n",
       "      <th>words1</th>\n",
       "      <th>words2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nos alojamos en una casa alquilada en la ciuda...</td>\n",
       "      <td>4</td>\n",
       "      <td>416</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>aloj cas alquil ciud amurall parec tan segur c...</td>\n",
       "      <td>[alojamos, casa, alquilada, ciudad, amurallada...</td>\n",
       "      <td>[aloj, cas, alquil, ciud, amurall, parec, tan,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La comida está bien, pero nada especial. Yo te...</td>\n",
       "      <td>3</td>\n",
       "      <td>263</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>com bien especial mejor com mexc unid margarit...</td>\n",
       "      <td>[comida, bien, especial, mejor, comida, mexcan...</td>\n",
       "      <td>[com, bien, especial, mejor, com, mexc, unid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En mi opinión, no es una como muchos usuarios ...</td>\n",
       "      <td>3</td>\n",
       "      <td>612</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>opinion usuari reclam gran palad parec ser par...</td>\n",
       "      <td>[opinión, usuarios, reclaman, gran, paladar, p...</td>\n",
       "      <td>[opinion, usuari, reclam, gran, palad, parec, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>esta curiosa forma que asemeja una silla de mo...</td>\n",
       "      <td>4</td>\n",
       "      <td>180</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>curios form asemej sill mont ahi nombr icon ci...</td>\n",
       "      <td>[curiosa, forma, asemeja, silla, montar, ahi, ...</td>\n",
       "      <td>[curios, form, asemej, sill, mont, ahi, nombr,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lo mejor era la limonada. Me gusto la comida d...</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>mejor limon gust com mund sos fri</td>\n",
       "      <td>[mejor, limonada, gusto, comida, mundo, sosa, ...</td>\n",
       "      <td>[mejor, limon, gust, com, mund, sos, fri]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7870</th>\n",
       "      <td>El motivo de mi estancia fue porque vine a un ...</td>\n",
       "      <td>3</td>\n",
       "      <td>624</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>motiv estanci vin congres medic hosped lug ins...</td>\n",
       "      <td>[motivo, estancia, vine, congreso, medico, hos...</td>\n",
       "      <td>[motiv, estanci, vin, congres, medic, hosped, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7871</th>\n",
       "      <td>Es difícil revisar el castillo porque apenas p...</td>\n",
       "      <td>3</td>\n",
       "      <td>609</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>dificil revis castill apen pod camin sofoc cal...</td>\n",
       "      <td>[difícil, revisar, castillo, apenas, podíamos,...</td>\n",
       "      <td>[dificil, revis, castill, apen, pod, camin, so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7872</th>\n",
       "      <td>Si vas a Mérida no puedes perderte de este lug...</td>\n",
       "      <td>5</td>\n",
       "      <td>168</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>si vas mer pued perdert lug nuev sucursal ampl...</td>\n",
       "      <td>[si, vas, mérida, puedes, perderte, lugar, nue...</td>\n",
       "      <td>[si, vas, mer, pued, perdert, lug, nuev, sucur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7873</th>\n",
       "      <td>Este imperdible sitio, que lleva el nombre de ...</td>\n",
       "      <td>5</td>\n",
       "      <td>424</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>imperd siti llev nombr conquist joy urbanasu a...</td>\n",
       "      <td>[imperdible, sitio, lleva, nombre, conquistado...</td>\n",
       "      <td>[imperd, siti, llev, nombr, conquist, joy, urb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7874</th>\n",
       "      <td>Festejando Dia de el Amor y Amistad\\r\\n\\r\\nTe ...</td>\n",
       "      <td>3</td>\n",
       "      <td>265</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>festej dia amor amist remont restaur cafet par...</td>\n",
       "      <td>[festejando, dia, amor, amistad, remonta, rest...</td>\n",
       "      <td>[festej, dia, amor, amist, remont, restaur, ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7875 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review  Class  NumPalabras  \\\n",
       "0     Nos alojamos en una casa alquilada en la ciuda...      4          416   \n",
       "1     La comida está bien, pero nada especial. Yo te...      3          263   \n",
       "2     En mi opinión, no es una como muchos usuarios ...      3          612   \n",
       "3     esta curiosa forma que asemeja una silla de mo...      4          180   \n",
       "4     Lo mejor era la limonada. Me gusto la comida d...      2           88   \n",
       "...                                                 ...    ...          ...   \n",
       "7870  El motivo de mi estancia fue porque vine a un ...      3          624   \n",
       "7871  Es difícil revisar el castillo porque apenas p...      3          609   \n",
       "7872  Si vas a Mérida no puedes perderte de este lug...      5          168   \n",
       "7873  Este imperdible sitio, que lleva el nombre de ...      5          424   \n",
       "7874  Festejando Dia de el Amor y Amistad\\r\\n\\r\\nTe ...      3          265   \n",
       "\n",
       "      Moda  Max  Min                                              words  \\\n",
       "0        2   13    1  aloj cas alquil ciud amurall parec tan segur c...   \n",
       "1        2   14    1  com bien especial mejor com mexc unid margarit...   \n",
       "2        3   16    1  opinion usuari reclam gran palad parec ser par...   \n",
       "3        2    9    2  curios form asemej sill mont ahi nombr icon ci...   \n",
       "4        2    9    1                  mejor limon gust com mund sos fri   \n",
       "...    ...  ...  ...                                                ...   \n",
       "7870     2   13    0  motiv estanci vin congres medic hosped lug ins...   \n",
       "7871     2   15    1  dificil revis castill apen pod camin sofoc cal...   \n",
       "7872     3    9    1  si vas mer pued perdert lug nuev sucursal ampl...   \n",
       "7873     2   18    0  imperd siti llev nombr conquist joy urbanasu a...   \n",
       "7874     2   13    0  festej dia amor amist remont restaur cafet par...   \n",
       "\n",
       "                                                 words1  \\\n",
       "0     [alojamos, casa, alquilada, ciudad, amurallada...   \n",
       "1     [comida, bien, especial, mejor, comida, mexcan...   \n",
       "2     [opinión, usuarios, reclaman, gran, paladar, p...   \n",
       "3     [curiosa, forma, asemeja, silla, montar, ahi, ...   \n",
       "4     [mejor, limonada, gusto, comida, mundo, sosa, ...   \n",
       "...                                                 ...   \n",
       "7870  [motivo, estancia, vine, congreso, medico, hos...   \n",
       "7871  [difícil, revisar, castillo, apenas, podíamos,...   \n",
       "7872  [si, vas, mérida, puedes, perderte, lugar, nue...   \n",
       "7873  [imperdible, sitio, lleva, nombre, conquistado...   \n",
       "7874  [festejando, dia, amor, amistad, remonta, rest...   \n",
       "\n",
       "                                                 words2  \n",
       "0     [aloj, cas, alquil, ciud, amurall, parec, tan,...  \n",
       "1     [com, bien, especial, mejor, com, mexc, unid, ...  \n",
       "2     [opinion, usuari, reclam, gran, palad, parec, ...  \n",
       "3     [curios, form, asemej, sill, mont, ahi, nombr,...  \n",
       "4             [mejor, limon, gust, com, mund, sos, fri]  \n",
       "...                                                 ...  \n",
       "7870  [motiv, estanci, vin, congres, medic, hosped, ...  \n",
       "7871  [dificil, revis, castill, apen, pod, camin, so...  \n",
       "7872  [si, vas, mer, pued, perdert, lug, nuev, sucur...  \n",
       "7873  [imperd, siti, llev, nombr, conquist, joy, urb...  \n",
       "7874  [festej, dia, amor, amist, remont, restaur, ca...  \n",
       "\n",
       "[7875 rows x 9 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Unificación de las palabras\n",
    "molData=prepData.copy()\n",
    "molData['words'] = molData['words2'].apply(lambda x: ' '.join(map(str, x)))\n",
    "molData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Crea el test y el train set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(molData['words'], molData['Class'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6300, 12922)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train_transformed  = vectorizer.fit_transform(X_train)\n",
    "X_test_transformed = vectorizer.transform(X_test)\n",
    "print(X_train_transformed .shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid= TfidfTransformer(use_idf=True, norm='l2', smooth_idf=True)\n",
    "X_train_transformed=tfid.fit_transform(X_train_transformed)\n",
    "X_test_transformed=tfid.transform(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4653968253968254\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train logistic regression model\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "logistic_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Predictions on test data\n",
    "y_pred = logistic_model.predict(X_test_transformed)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.43682539682539684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC(random_state=42)\n",
    "svm.fit(X_train_transformed, y_train)\n",
    "y_pred_svm_sample = svm.predict(X_test_transformed)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm_sample)\n",
    "print(\"Accuracy:\", accuracy_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4685714285714286\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train Random Forest on the reduced dataset\n",
    "random_forest_sample = RandomForestClassifier(random_state=42)\n",
    "random_forest_sample.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Predict on the test set and calculate accuracy\n",
    "y_pred_rf_sample = random_forest_sample.predict(X_test_transformed)\n",
    "accuracy_rf_sample = accuracy_score(y_test, y_pred_rf_sample)\n",
    "\n",
    "print(\"Accuracy:\",accuracy_rf_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.433015873015873"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the neural network model\n",
    "# Let's use a simple architecture with two hidden layers of 100 neurons each\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=300, activation='relu', solver='adam', random_state=42)\n",
    "\n",
    "# Train the neural network on the reduced dataset\n",
    "mlp.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Predict on the test set and calculate accuracy\n",
    "y_pred_mlp = mlp.predict(X_test_transformed)\n",
    "accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "\n",
    "accuracy_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9574603174603175\n"
     ]
    }
   ],
   "source": [
    "#DecisionTree\n",
    "# Initialize the Decision Tree Regressor\n",
    "decision_tree_regressor = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Train the regressor on the reduced dataset\n",
    "decision_tree_regressor.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_dtr = decision_tree_regressor.predict(X_test_transformed)\n",
    "\n",
    "# For regression tasks, we typically use different metrics than accuracy, such as Mean Absolute Error (MAE)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, y_pred_dtr)\n",
    "\n",
    "### Menos es mejor\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] END clf__C=1.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n",
      "[CV] END clf__C=1.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n",
      "[CV] END clf__C=1.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n",
      "[CV] END clf__C=1.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n",
      "[CV] END clf__C=1.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   5.6s\n",
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n",
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n",
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n",
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n",
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   6.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   5.6s\n",
      "[CV] END clf__C=10.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n",
      "[CV] END clf__C=10.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n",
      "[CV] END clf__C=10.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n",
      "[CV] END clf__C=10.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n",
      "[CV] END clf__C=10.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   6.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   6.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   7.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   7.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   6.6s\n",
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n",
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n",
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n",
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n",
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   5.9s\n",
      "[CV] END clf__C=100.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n",
      "[CV] END clf__C=100.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n",
      "[CV] END clf__C=100.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n",
      "[CV] END clf__C=100.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n",
      "[CV] END clf__C=100.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=100.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   8.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=100.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   7.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=100.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   8.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=100.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   7.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=100.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   7.3s\n",
      "[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n",
      "[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n",
      "[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n",
      "[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n",
      "[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   6.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   6.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   6.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>; total time=   6.8s\n",
      "[CV] END clf__C=1.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n",
      "[CV] END clf__C=1.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n",
      "[CV] END clf__C=1.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n",
      "[CV] END clf__C=1.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n",
      "[CV] END clf__C=1.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   6.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   5.3s\n",
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n",
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n",
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n",
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n",
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   9.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   9.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=  10.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=  10.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=  10.0s\n",
      "[CV] END clf__C=10.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n",
      "[CV] END clf__C=10.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n",
      "[CV] END clf__C=10.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n",
      "[CV] END clf__C=10.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n",
      "[CV] END clf__C=10.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   7.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   7.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   5.9s\n",
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n",
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n",
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n",
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n",
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=  10.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   9.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=  11.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=  11.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   8.6s\n",
      "[CV] END clf__C=100.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n",
      "[CV] END clf__C=100.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n",
      "[CV] END clf__C=100.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n",
      "[CV] END clf__C=100.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n",
      "[CV] END clf__C=100.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=100.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=100.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=100.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=100.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=100.0, clf__penalty=l1, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   6.4s\n",
      "[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n",
      "[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n",
      "[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n",
      "[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n",
      "[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words={'suyas', 'tenemos', 'sois', 'hemos', 'fuiste', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'}, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   9.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   9.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   8.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   9.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>, vect__use_idf=False; total time=   9.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "60 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "  File \"c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\memory.py\", line 353, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 2138, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "  File \"c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'stop_words' parameter of TfidfVectorizer must be a str among {'english'}, an instance of 'list' or None. Got {'tenemos', 'suyas', 'sois', 'fuiste', 'hemos', 'hubo', 'del', 'uno', 'tiene', 'este', 'seremos', 'y', 'nosotras', 'serás', 'tuviéramos', 'al', 'vosotros', 'estuviéramos', 'sentida', 'hayas', 'erais', 'ese', 'tendréis', 'estábamos', 'estéis', 'mías', 'sería', 'nuestro', 'estuvo', 'estuviera', 'fue', 'estaría', 'habréis', 'tienes', 'estuve', 'tendrá', 'habrías', 'tuya', 'algunos', 'estamos', 'seríamos', 'hubierais', 'lo', 'algunas', 'donde', 'el', 'tenidos', 'como', 'tenida', 'tenga', 'contra', 'esté', 'hubieron', 'habrían', 'estuvieses', 'antes', 'les', 'tengan', 'suyos', 'estando', 'tened', 'esa', 'sobre', 'habrán', 'hubiesen', 'tendremos', 'estaba', 'tenía', 'seamos', 'estuvieran', 'estarías', 'estuvisteis', 'tuviesen', 'estabais', 'estaremos', 'algo', 'otras', 'tenidas', 'habían', 'estada', 'eras', 'os', 'o', 'estabas', 'las', 'tendrías', 'había', 'hayan', 'teníamos', 'estuviesen', 'será', 'te', 'mi', 'tuvieses', 'fuimos', 'pero', 'fueras', 'sentidas', 'estadas', 'estés', 'es', 'nuestras', 'tengas', 'fuisteis', 'tengo', 'otro', 'estuviésemos', 'a', 'habrá', 'muchos', 'hayáis', 'hubieran', 'poco', 'seáis', 'ha', 'estar', 'fuéramos', 'tendríais', 'más', 'nuestra', 'tuvo', 'fuese', 'nada', 'quienes', 'tuvieran', 'vuestras', 'habrás', 'que', 'somos', 'hubieses', 'tus', 'seríais', 'he', 'e', 'estados', 'serían', 'ni', 'está', 'sintiendo', 'nuestros', 'su', 'tendría', 'los', 'están', 'vosotras', 'ya', 'la', 'habré', 'quien', 'durante', 'qué', 'tuve', 'en', 'habías', 'todo', 'muy', 'hayamos', 'él', 'tuviese', 'habidos', 'fuera', 'tienen', 'tú', 'seréis', 'habido', 'tengáis', 'tuvieseis', 'estaban', 'habremos', 'fueran', 'habíamos', 'una', 'tuvieron', 'otra', 'has', 'esto', 'estás', 'para', 'le', 'tu', 'tuvieras', 'estáis', 'hubieras', 'tenéis', 'tenías', 'suya', 'habría', 'con', 'estaríais', 'tuviésemos', 'ellas', 'ella', 'tuyos', 'hubiese', 'tenido', 'habidas', 'estoy', 'habida', 'entre', 'habiendo', 'eso', 'esta', 'nosotros', 'cuando', 'habíais', 'tuviste', 'fuerais', 'tendrán', 'sea', 'todos', 'son', 'fueses', 'estarían', 'hubiera', 'serías', 'seré', 'esos', 'serán', 'no', 'desde', 'mío', 'hubieseis', 'hubiste', 'tuvisteis', 'míos', 'eran', 'hubiéramos', 'fuésemos', 'ellos', 'estad', 'yo', 'me', 'también', 'ti', 'mí', 'porque', 'tendrás', 'teníais', 'mucho', 'tuyas', 'ante', 'estuvimos', 'tuyo', 'un', 'sentidos', 'hubiésemos', 'hay', 'estuvieron', 'vuestros', 'por', 'sentid', 'esas', 'cual', 'estarán', 'estaríamos', 'estará', 'fueseis', 'tuvimos', 'mis', 'tendríamos', 'nos', 'de', 'han', 'fuesen', 'estaréis', 'mía', 'habríamos', 'estuvierais', 'sus', 'sí', 'hube', 'vuestra', 'sin', 'otros', 'tuvierais', 'estemos', 'éramos', 'era', 'sentido', 'suyo', 'estuviese', 'fui', 'haya', 'seas', 'estuviste', 'tendré', 'tengamos', 'se', 'eres', 'sean', 'hubisteis', 'estaré', 'estarás', 'teniendo', 'estado', 'tanto', 'habríais', 'siente', 'tendrían', 'soy', 'hubimos', 'estos', 'estas', 'hasta', 'estuvieseis', 'unos', 'habéis', 'fueron', 'tenían', 'vuestro', 'estuvieras', 'tuviera', 'estén'} instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan 0.46555556        nan 0.4847619         nan 0.45190476\n",
      "        nan 0.48714286        nan 0.44428571        nan 0.46746032\n",
      "        nan 0.45603175        nan 0.47095238        nan 0.44444444\n",
      "        nan 0.45920635        nan 0.44015873        nan 0.45190476]\n",
      "  warnings.warn(\n",
      "c:\\Users\\esteb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vect&#x27;, TfidfVectorizer()),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        LogisticRegression(random_state=0,\n",
       "                                                           solver=&#x27;liblinear&#x27;))]),\n",
       "             n_jobs=1,\n",
       "             param_grid=[{&#x27;clf__C&#x27;: [1.0, 10.0, 100.0],\n",
       "                          &#x27;clf__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                          &#x27;vect__ngram_range&#x27;: [(1, 1)],\n",
       "                          &#x27;vect__stop_words&#x27;: [{&#x27;a&#x27;, &#x27;al&#x27;, &#x27;algo&#x27;, &#x27;algunas&#x27;,\n",
       "                                                &#x27;algunos&#x27;, &#x27;ante&#x27;, &#x27;antes&#x27;,\n",
       "                                                &#x27;como&#x27;, &#x27;con&#x27;, &#x27;contra&#x27;, &#x27;cual&#x27;,\n",
       "                                                &#x27;cuando&#x27;, &#x27;d...\n",
       "                          &#x27;vect__stop_words&#x27;: [{&#x27;a&#x27;, &#x27;al&#x27;, &#x27;algo&#x27;, &#x27;algunas&#x27;,\n",
       "                                                &#x27;algunos&#x27;, &#x27;ante&#x27;, &#x27;antes&#x27;,\n",
       "                                                &#x27;como&#x27;, &#x27;con&#x27;, &#x27;contra&#x27;, &#x27;cual&#x27;,\n",
       "                                                &#x27;cuando&#x27;, &#x27;de&#x27;, &#x27;del&#x27;, &#x27;desde&#x27;,\n",
       "                                                &#x27;donde&#x27;, &#x27;durante&#x27;, &#x27;e&#x27;, &#x27;el&#x27;,\n",
       "                                                &#x27;ella&#x27;, &#x27;ellas&#x27;, &#x27;ellos&#x27;, &#x27;en&#x27;,\n",
       "                                                &#x27;entre&#x27;, &#x27;era&#x27;, &#x27;erais&#x27;, &#x27;eran&#x27;,\n",
       "                                                &#x27;eras&#x27;, &#x27;eres&#x27;, &#x27;es&#x27;, ...},\n",
       "                                               None],\n",
       "                          &#x27;vect__tokenizer&#x27;: [&lt;function nltk_spanish_tokenizer at 0x000001F7423ED9D0&gt;],\n",
       "                          &#x27;vect__use_idf&#x27;: [False]}],\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vect&#x27;, TfidfVectorizer()),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        LogisticRegression(random_state=0,\n",
       "                                                           solver=&#x27;liblinear&#x27;))]),\n",
       "             n_jobs=1,\n",
       "             param_grid=[{&#x27;clf__C&#x27;: [1.0, 10.0, 100.0],\n",
       "                          &#x27;clf__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                          &#x27;vect__ngram_range&#x27;: [(1, 1)],\n",
       "                          &#x27;vect__stop_words&#x27;: [{&#x27;a&#x27;, &#x27;al&#x27;, &#x27;algo&#x27;, &#x27;algunas&#x27;,\n",
       "                                                &#x27;algunos&#x27;, &#x27;ante&#x27;, &#x27;antes&#x27;,\n",
       "                                                &#x27;como&#x27;, &#x27;con&#x27;, &#x27;contra&#x27;, &#x27;cual&#x27;,\n",
       "                                                &#x27;cuando&#x27;, &#x27;d...\n",
       "                          &#x27;vect__stop_words&#x27;: [{&#x27;a&#x27;, &#x27;al&#x27;, &#x27;algo&#x27;, &#x27;algunas&#x27;,\n",
       "                                                &#x27;algunos&#x27;, &#x27;ante&#x27;, &#x27;antes&#x27;,\n",
       "                                                &#x27;como&#x27;, &#x27;con&#x27;, &#x27;contra&#x27;, &#x27;cual&#x27;,\n",
       "                                                &#x27;cuando&#x27;, &#x27;de&#x27;, &#x27;del&#x27;, &#x27;desde&#x27;,\n",
       "                                                &#x27;donde&#x27;, &#x27;durante&#x27;, &#x27;e&#x27;, &#x27;el&#x27;,\n",
       "                                                &#x27;ella&#x27;, &#x27;ellas&#x27;, &#x27;ellos&#x27;, &#x27;en&#x27;,\n",
       "                                                &#x27;entre&#x27;, &#x27;era&#x27;, &#x27;erais&#x27;, &#x27;eran&#x27;,\n",
       "                                                &#x27;eras&#x27;, &#x27;eres&#x27;, &#x27;es&#x27;, ...},\n",
       "                                               None],\n",
       "                          &#x27;vect__tokenizer&#x27;: [&lt;function nltk_spanish_tokenizer at 0x000001F7423ED9D0&gt;],\n",
       "                          &#x27;vect__use_idf&#x27;: [False]}],\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 LogisticRegression(random_state=0, solver=&#x27;liblinear&#x27;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(random_state=0, solver=&#x27;liblinear&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vect', TfidfVectorizer()),\n",
       "                                       ('clf',\n",
       "                                        LogisticRegression(random_state=0,\n",
       "                                                           solver='liblinear'))]),\n",
       "             n_jobs=1,\n",
       "             param_grid=[{'clf__C': [1.0, 10.0, 100.0],\n",
       "                          'clf__penalty': ['l1', 'l2'],\n",
       "                          'vect__ngram_range': [(1, 1)],\n",
       "                          'vect__stop_words': [{'a', 'al', 'algo', 'algunas',\n",
       "                                                'algunos', 'ante', 'antes',\n",
       "                                                'como', 'con', 'contra', 'cual',\n",
       "                                                'cuando', 'd...\n",
       "                          'vect__stop_words': [{'a', 'al', 'algo', 'algunas',\n",
       "                                                'algunos', 'ante', 'antes',\n",
       "                                                'como', 'con', 'contra', 'cual',\n",
       "                                                'cuando', 'de', 'del', 'desde',\n",
       "                                                'donde', 'durante', 'e', 'el',\n",
       "                                                'ella', 'ellas', 'ellos', 'en',\n",
       "                                                'entre', 'era', 'erais', 'eran',\n",
       "                                                'eras', 'eres', 'es', ...},\n",
       "                                               None],\n",
       "                          'vect__tokenizer': [<function nltk_spanish_tokenizer at 0x000001F7423ED9D0>],\n",
       "                          'vect__use_idf': [False]}],\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tfidf = TfidfVectorizer(strip_accents=None,\n",
    "#                          lowercase=False,\n",
    "#                          preprocessor=None)\n",
    "# param_grid = [{'vect__ngram_range': [(1,1)],\n",
    "#                 'vect__stop_words': [spanish_stopwords, None],\n",
    "#                 'vect__tokenizer': [nltk_spanish_tokenizer],\n",
    "#                 'clf__penalty': ['l1', 'l2'],\n",
    "#                 'clf__C': [1.0, 10.0, 100.0]},\n",
    "#                {'vect__ngram_range': [(1,1)],\n",
    "#                 'vect__stop_words': [spanish_stopwords, None],\n",
    "#                 'vect__tokenizer': [nltk_spanish_tokenizer],\n",
    "#                 'vect__use_idf':[False],\n",
    "#                 'vect__norm':[None],\n",
    "#                 'clf__penalty': ['l1', 'l2'],\n",
    "#                 'clf__C': [1.0, 10.0, 100.0]}\n",
    "#               ]\n",
    "# lr_tfidf = Pipeline([('vect', tfidf),\n",
    "#                       ('clf',\n",
    "#                        LogisticRegression(random_state=0,\n",
    "#                                           solver='liblinear'))])\n",
    "# gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid,\n",
    "#                             scoring='accuracy',\n",
    "#                             cv=5, verbose=2,\n",
    "#                             n_jobs=1)\n",
    " \n",
    "# gs_lr_tfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set: {'clf__C': 10.0, 'clf__penalty': 'l2', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function nltk_spanish_tokenizer at 0x000001F7423ED9D0>} \n"
     ]
    }
   ],
   "source": [
    "# print('Best parameter set: %s ' % gs_lr_tfidf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.487\n"
     ]
    }
   ],
   "source": [
    "# print('CV Accuracy: %.3f'      % gs_lr_tfidf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = gs_lr_tfidf.best_estimator_\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
